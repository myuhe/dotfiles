これは $s、  $s より makeinfo バージョン  $s によって作成されました。

INFO-DIR-SECTION Network Applications
START-INFO-DIR-ENTRY
* Wget(ja): (wget-ja).         The non-interactive network downloader.
END-INFO-DIR-ENTRY

   This file documents the the GNU Wget utility for downloading network
data.

   Copyright (C) 1996, 1997, 1998, 2000, 2001, 2002, 2003 Free Software
Foundation, Inc.

   Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

   Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.1 or
any later version published by the Free Software Foundation; with the
Invariant Sections being "GNU General Public License" and "GNU Free
Documentation License", with no Front-Cover Texts, and with no
Back-Cover Texts.  A copy of the license is included in the section
entitled "GNU Free Documentation License".


File: wget-ja.info,  Node: Top,  Next: Overview,  Prev: (dir),  Up: (dir)

Wget 1.9
********

   このマニュアルは，GNU Wgetのバージョン1.9を説明した文章で，
それはネットワークでのダウンロードで自由に利用可能なユーティリティです．

   Copyright (C) 1996, 1997, 1998, 2000, 2001, 2003 Free Software
Foundation, Inc.

* Menu:

* Overview::            Features of Wget.
* Invoking::            Wget command-line arguments.
* Recursive Retrieval:: Description of recursive retrieval.
* Following Links::     The available methods of chasing links.
* Time-Stamping::       Mirroring according to time-stamps.
* Startup File::        Wget's initialization file.
* Examples::            Examples of usage.
* Various::             The stuff that doesn't fit anywhere else.
* Appendices::          Some useful references.
* Copying::             You may give out copies of Wget and of this manual.
* Concept Index::       Topics covered by this manual.


File: wget-ja.info,  Node: Overview,  Next: Invoking,  Prev: Top,  Up: Top

概要
****

   GNU Wgetは，Webから対話的ではないファイルのダウンロードを行なうための
フリーのユーティリティです．HTTP，HTTPS，そしてFTPをサ
ポートしていて，HTTPプロキシからの回収も同様にサポートしています．

   この章は，Wgetの機能の部分的な概要となっています．

   *
     Wgetは対話的ではなく，つまりそれはユーザがログオンしていない間にバック
     グラウンドで動作可能なことを意味しています．このため，Wgetに仕事を完了
     させるため，回収を開始し，システムとの接続を終了する(システムと離れて
     いる)ことが可能になっています．それと比較して，ほとんどのウェブブラウ
     ザは常にユーザの存在を要求し，それは大量のデータを転送しているときは，
     大きな障害となります．


   * Wgetは，HTMLページとXHTMLページのリンクをたどり，遠隔地のウェ
     ブサイトのローカルバージョンを作成し，それはオリジナルサイトのディレク
     トリ構造を完全に再生成します．これは"再帰的なダウンロード"と言われる
     こともあります．こうしている間，WgetはRobot Exclusion Standard
     (`/robots.txt')を考慮します．オフラインで閲覧するために，ダウンロー
     ドされたHTMLファイルのリンクをローカルのファイルに変換するよう，
     Wgetに指示することが可能です．


   *
     ファイル名のワイルドカードへの一致と，ディレクトリの再帰的なミラーは，
     FTPで回収するときに利用可能です．Wgetは，HTTPサーバと
     FTPサーバの両方でタイムスタンプ情報を読み込み，それをローカルに保
     存することが可能です．それにより，Wgetはリモートファイルが前回の回収か
     ら変化しているかどうかを理解し，変化がある場合は新しいバージョンを自動
     的に回収することが可能になっています．これで，Wgetがホームページと同様
     にFTPサイトのミラーに適するようになっています．


   *
     Wgetは，遅く不安定なネットワークの接続越しでも耐性があるように設計され
     ました．ネットワークの問題でダウンロードに失敗した場合，ファイル全体が
     回収されるまで再試行を続けます．サーバがリゲットをサポートしている場合，
     残っている場所からダウンロードを続けるようサーバに伝えます．


   *
     Wgetはプロキシサーバをサポートし，それはネットワークの負荷を軽くし，回
     収の速度を上げ，そしてファイアーウォールの裏からのアクセスを提供するこ
     とを可能にします．しかし，socks形式のゲートウェイの使用が必要なファイ
     アーウォールの裏にいる場合，socksライブラリを入手しsocksサポートを用い
     てWgetをビルドすることが可能です．Wgetは，受動的なFTPダウンロード
     もオプションとしてサポートしています．


   *
     組込みの機能は，希望するリンクをたどることを調整するメカニズムを提供し
     ます(*note Following Links::)．


   *
     回収は通常，ドットを出力しながら追跡し，それぞれのドットは受信したデー
     タの固定量(デフォルトで1KB)を表現しています．これらの表現は好みにより
     カスタマイズ可能です．


   *
     ほとんどの機能は完全に構成を変更することができ，それらは，コマンドライ
     ンオプションや初期化ファイル`.wgetrc'(*note Startup File::)を通じ
     て行います．Wgetでは，サイト設定に対して"グローバルな"スタートアッ
     プファイル(デフォルトで`/usr/local/etc/wgetrc')で定義可能になって
     います．


   * 最後になりますが，GNU
     Wgetはフリーソフトウェアです．このことは，Free Software
     Foundationが出版しているGNU一般公有使用許諾書 (*note
     Copying::)の用語の下で，誰もが，使用し，再配布し，そして/または
     修正が可能だということを意味します．


File: wget-ja.info,  Node: Invoking,  Next: Recursive Retrieval,  Prev: Overview,  Up: Top

呼び出し
********

デフォルトで，Wgetの呼び出しは非常に簡単です．基本的な構文は以下の通り
です．

     wget [OPTION]... [URL]...

   Wgetは，コマンドラインで指定された全てのURLを，単純にダウンロード
します．URLは，以下で定義されるような"Uniform Resource Locator"です．

しかし，Wgetのデフォルトパラメータをいくつか変更したいかもしれません．
そうするためには二つの方法が利用可能です．永久的に適切なコマンドを
`.wgetrc' (*note Startup File::)に追加する方法と，コマンドライン
で指定する方法です．

* Menu:

* URL Format::
* Option Syntax::
* Basic Startup Options::
* Logging and Input File Options::
* Download Options::
* Directory Options::
* HTTP Options::
* FTP Options::
* Recursive Retrieval Options::
* Recursive Accept/Reject Options::


File: wget-ja.info,  Node: URL Format,  Next: Option Syntax,  Prev: Invoking,  Up: Invoking

URLの書式
=========

   "URL"は，Uniform Resource Locatorの略語です．uniform resource
locatorはインターネットで利用可能なリソースに対するコンパクトな文字列
表示です．WgetはURL構文をRFC1738に従って理解します．これは，
最も広く使用されている形式です(角カッコはオプション部分を意味します)．

     http://host[:port]/directory/file
     ftp://host[:port]/directory/file

   ユーザ名とパスワードをURL内部に符号化できます．

     ftp://user:password@host/path
     http://user:password@host/path

   USERまたはPASSWORDのどちらか，または両方とも無くても構いま
せん．HTTPユーザ名やパスワードのどちらか一方を省いている場合，認
証は送られません．FTPユーザ名を省いている場合，`anonymous'が
使用されます．FTPパスワードを省いている場合，電子メールのアドレス
がデフォルトパスワードとして提供されます．(1)

   *重要な注意*：コマンドラインでパスワードを含むURLを指定し
た場合，ユーザ名とパスワードは，`ps'を使用することで，システム上
のすべてのユーザがそのまま見えることになります．複数のユーザのシステム
では，これは大きなセキュリティ上の問題になります．それを回避するために
`wget -i -'を使用し，それぞれを別の行にして`C-d'で終わりにし
たURLをWgetの標準入力に与えて下さい

   URLでの安全ではない符号化は`%xy'で可能で，`xy'は文字の
ASCII値の16進数の表現です．一般的な安全でない文字は，`%'
(`%25'として引用されます)，`:' (`%3A'として引用されます)， そして`@'
(`%40'として引用されます)が含まれます．安全でない
文字の包括的なリストは，RFC1738を参照してください．

   Wgetは，FTP URLに対する`type'の機能もサポートします．デ
フォルトで，FTPドキュメントはバイナリモードで回収(type `i')
し，それはダウンロードで変更されないことを意味します．その他の役に立つ
モードは`a' ("ASCII")モードで，それは異なるオペレーティングシ
ステムの間で行の分離文字を変換し，そのためそれはテキストファイルで役に
立ちます．例は以下のようになります．

     ftp://host/directory/file;type=a

   歴史的(ヒステリック?)な理由と広範囲で使用されていることから，URL
指定の代替となる変種もサポートされています．

   FTP-only syntax (`NcFTP'でサポートされました):
     host:/dir/file

   HTTP-only syntax (`Netscape'で導入されました):
     host[:port]/dir/file

これら二つの代替形式は推奨されず，将来のサポートはやめるかもしれません．

   これらの表記の違いを理解できなかったり，その使い方を知らない場合，
`Lynx'や`Netscape'のような好みのブラウザで使用するプレーンな
普通の書式を使用してください．

   ---------- Footnotes ----------

   (1) ホームディレクトリ
に`.netrc'ファイルがある場合，パスワードはそこで検索されます．


File: wget-ja.info,  Node: Option Syntax,  Next: Basic Startup Options,  Prev: URL Format,  Up: Invoking

オプションの構文
================

   Wgetは，引数の処理にGNU getoptsを使用しているので，全てのオプションに
は短い形式と長い形式があります．長いオプションは覚え易くより便利なので
すが，入力に時間がかかります．異なるオプションスタイルを自由に混ぜて使
用したり，コマンドライン引数の後にオプションを指定したりしてもかまいま
せん．このため，以下のように書くことができます．

     wget -r --tries=10 http://fly.srk.fer.hr/ -o log

オプションを受け入れる引数とその引数の間のスペースは省略してもかまいま
せん．`-o log'の代わりに`-olog'と書くことができます．

引数が不要な複数のオプションを，以下のようにまとめて書き込んでもかまい
ません．

     wget -drc URL

   これは，以下と完全に等価です．

     wget -d -r -c URL

   オプションは引数の後に指定できるので，それらは`--'で終端すること
ができます．そのため，以下ではURL `-x'をダウンロードしようと
し，`log'に失敗を報告します．

     wget -o log -- -x

カンマで分離されているリストを受け入れるすべてのオプションは，空のリス
トの指定がその値をクリアするという規則に従います．これは，
`.wgetrc'の設定をクリアにするとき役に立つはずです．例えば，
`.wgetrc'が`exclude_directories'を`/cgi-bin'に設定する
場合，以下の例では最初にリセットし，除外するものとして`/~nobody'
と`/~somebody'を設定します．`.wgetrc' (*note Wgetrc
Syntax::)のリストをクリアにすることも可能です．

     wget -X '' -X /~nobody,/~somebody


File: wget-ja.info,  Node: Basic Startup Options,  Next: Logging and Input File Options,  Prev: Option Syntax,  Up: Invoking

基本的なスタートアップオプション
================================

`-V'
`--version'
     Wgetのバージョンを表示します．

`-h'
`--help'
     Wgetのすべてのコマンドラインオプションを記述するヘルプメッセージを出力
     します．

`-b'
`--background'
     開始直後にバックグラウンドに移行します．出力ファイルを`-o'で指定
     していない場合，出力は`wget-log'にリダイレクトされます．

`-e COMMAND'
`--execute COMMAND'
     `.wgetrc' (*note Startup File::)の一部のように，COMMANDを実
     行します．このようなコマンドは`.wgetrc'のコマンドの_後に_実
     行されるので，それらに優先します．


File: wget-ja.info,  Node: Logging and Input File Options,  Next: Download Options,  Prev: Basic Startup Options,  Up: Invoking

ログと入力ファイルオプション
============================

`-o LOGFILE'
`--output-file=LOGFILE'
     全てのメッセージをLOGFILEにログを取ります．メッセージは通常，標
     準エラー出力に報告されます．

`-a LOGFILE'
`--append-output=LOGFILE'
     LOGFILEに追加します．古いログファイルを上書きする代わりに
     LOGFILEに追加する以外，これは`-o'と同じです．LOGFILE
     が無い場合は，新しいファイルを作成します．

`-d'
`--debug'
     デバッグ出力を開始し，それは，Wgetが正確に動作しない場合，Wgetの開発に
     様々な重要な情報として意味があります．システム管理者が，デバッグサポー
     ト無しでWgetのコンパイルを選択している可能性もあり，その場合`-d'
     は動作しません．デバッグサポートでのコンパイルは常に安全だということに
     注意してください--デバッグサポートでコンパイルされたWgetは，`-d'
     が要求されるまでデバッグ情報を決して出力_しません_．バグレポート
     を送るために`-d'を使用する方法の詳細は，*Note Reporting Bugs::.

`-q'
`--quiet'
     Wgetの出力を停止します．

`-v'
`--verbose'
     利用可能な全てのデータを用いた冗長な出力を開始します．デフォルトの出力
     は冗長です．

`-nv'
`--non-verbose'
     冗長でない出力です--完全に静かにするのではなく(そうするには`-q'
     を使用してください)冗長を停止するということで，エラーメッセージと基本
     的な情報は，まだ出力されることを意味します．

`-i FILE'
`--input-file=FILE'
     FILEからURLを読み込み，その場合はURLをコマンドラインに
     書く必要はありません．コマンド行と入力ファイルの両方にURLがある場
     合，コマンド行のものが最初に回収されます．FILEはHTMLドキュ
     メントにする必要はありません(しかし，害が無い場合です)--URLだけ
     順番にリストアップされている場合はそれで十分です．

     しかし，`--force-html'を指定した場合，ドキュメントは`html'と
     見なされます．この状況では相対的なリンクに問題がある可能性もあり，それ
     は，`<base href="URL">'をドキュメントに加えたり，コマンドラ
     インで`--base=URL'を指定することで解決できます．

`-F'
`--force-html'
     ファイルから入力を読み込むとき，HTMLファイルとして扱うことを強制
     します．これで，ローカルディスクの既存のHTMLファイルからの相対的
     なリンクを，HTMLに`<base href="URL">'を加えたり，
     `--base'コマンドラインオプションを使用することで回収できるように
     なります．

`-B URL'
`--base=URL'
     `-F'と結合して使用されるとき，`-i'で指定されるファイル内の相
     対リンクにURLを前置します．


File: wget-ja.info,  Node: Download Options,  Next: Directory Options,  Prev: Logging and Input File Options,  Up: Invoking

ダウンロードオプション
======================

`--bind-address=ADDRESS'
     クライアントのTCP/IP接続を作成するとき，ローカルマシンのADDRESS
     に`bind()'します．ADDRESSはホスト名またはIPアドレスとして指
     定してもかまいません．このオプションはマシンが複数のIPに連結されている
     場合，役に立つはずです．

`-t NUMBER'
`--tries=NUMBER'
     再試行の回数をNUMBERに設定します．無限の再試行のため，0や
     `inf'を指定してください．デフォルトの再試行は20回で，例外として
     "connection refused"や"not found" (404)のような致命的なエラーでは
     再試行しません．

`-O FILE'
`--output-document=FILE'
     ドキュメントは適切なファイルに書かれませんが，全て一緒に連結されて
     FILEに書き込まれます．FILEが既にある場合は上書きされます．
     FILEが`-'の場合はドキュメントは標準出力に書き込まれます．こ
     のオプションを含めると，再試行の回数を1に自動的に設定します．

`-nc'
`--no-clobber'
     同じディレクトリに一回以上ファイルがダウンロードされる場合，Wgetの動作
     は，`-nc'を含むいくつかのオプションに依存します．繰り返しのダウン
     ロードで，ローカルファイルは"破壊され"ることもあれば，上書きされる
     こともあります．それ以外ではそのまま残ります．

     `-N'，`-nc'，または`-r'を用いずにWgetを実行するとき，同
     じディレクトリにダウンロードされる同じファイルは，オリジナルがそのまま
     FILEのコピーとなり，二番目のコピーは`FILE.1'と命名さ
     れます．ファイルが再びダウンロードされた場合は，三番目のコピーは
     `FILE.2'となり，以下同様になります．`-nc'が指定された
     場合はこの動作が抑制され，Wgetはより新しい`FILE'のコピーの
     ダウンロードを拒否します．このため，"`no-clobber'"は実際にこの
     モードの間違った名称です--(数字の接尾子で既に破壊を妨げているので)そ
     れは破壊を妨げるのではなく，むしろ保存の複数のバージョンを持たないとい
     うことです．

     `-r'を用い，`-N'や`-nc'を用いずにWgetを実行したとき，ファ
     イルの再度のダウンロードは，古いものを単純に新しいコピーで上書きします．
     `-nc'を加えた場合はこの動作は妨げられ，オリジナルのバージョン保存
     し，サーバ上のあらゆるより新しいコピーを無視します．

     `-N'を用い，`-r'を用いるまたは用いないことで，Wgetを実行する
     とき，ローカルとリモートのファイルのタイムスタンプとサイズに依存して，
     より新しいファイルのダウンロードを実行するかどうかを決定します
     (*note Time-Stamping::)．`-nc'は`-N'と同時に指定できません．

     `-nc'が指定された場合，`.html'または(反吐がでる)`.htm'
     の接尾子を持つファイルは，Webから回収されているかのようにローカルディ
     スクからロードされて解析されることに注意して下さい．

`-c'
`--continue'
     部分的にダウンロードされたファイルの取得を続けます．これは，前回のWget
     のインスタンスや，他のプログラムで開始したダウンロードを完了したいとき
     便利です．例えば以下のようにします．

          wget -c ftp://sunsite.doc.ic.ac.uk/ls-lR.Z

     現在のディレクトリに`ls-lR.Z'という名前のファイルがある場合，Wget
     は，それがリモートファイルの最初の位置だと考え，ローカルファイルと同じ
     長さのオフセットから回収を続けるようサーバに依頼しみます．

     接続が中断されたファイルのダウンロードを再試行するために，現在のWget
     呼び出しを行いたいだけの場合は，このオプションを指定する必要がないこと
     に注意してください．これはデフォルトの動作です．`-c'は，Wgetの今
     回の呼び出しの_前に_開始したダウンロードの再開で，そのローカルファ
     イルがまだ完全ではないものにのみに効果があります．

     `-c'を用いない場合，前の例では，リモートファイルを `ls-lR.Z.1'
     にダウンロードし，途中で切られた`ls-lR.Z'ファイ
     ルはそのまま残ります．

     `-c'を空でないファイルで使用してWget 1.7を用いて開始すると，サー
     バが継続ダウンロードをサポートしていないことが判明した場合は，Wgetは最
     初からのダウンロードの開始を拒否するので，その影響で既存の内容がだめに
     なります．本当に最初からダウンロードを開始したい場合は，ファイルを削除
     してください．

     また，Wget 1.7を用いて開始すると，`-c'をサーバのファイルと同じ大
     きさでないファイルで使用する場合，Wgetはファイルのダウンロードを拒否し，
     そのことを説明メッセージを出力します．サーバのファイルがローカルのもの
     より小さいときも同じことが生じます--"続けること"に意味がなく，ダウ
     ンロードを行わないためです．

     反対に，`-c'を使用しているときは，ローカルより大きいサーバのファ
     イルは不完全なダウンロードとみなされ，`((リモートの)長さ - (ロー
     カルの)長さ)'バイトのみダウンロードされ，ローカルファイルの終りにくっ
     つけられます．この動作は場合によっては望ましくないものです--例えば，
     データコレクションやログファイルに追加された新しい部分をダウンロードす
     るために，`wget -c' を使用することが可能です．

     しかし，ファイルが，_追加されて_いるのではなく，_変更されて_
     いてサーバのものより大きい場合，おかしなファイルになります．Wgetには，
     ローカルのファイルがリモートファイルの前段が本当に有効だということを検
     証する方法がありません．`-r'と組合せて`-c'を使用するとき，す
     べてのファイルが"不完全なダウンロード"の候補と考慮されるので，このこと
     に特に注意する必要があります．

     `-c'を使用してみた場合におかしなファイルを得るもう一つの例は，ロー
     カルファイルに"transfer interrupted"文字列を挿入する，不完全な
     HTTPプロキシを使用している場合です．将来は，"rollback"オプショ
     ンがこの状況を扱うために追加されるかもしれません．

     `-c'は，FTPサーバと`Range'ヘッダをサポートするHTTP
     サーバのみで動作することに注意してください．

`--progress=TYPE'
     使用したい進行状況表示の形式を選択します．正当な表示は"ドット"と
     "バー" です．

     "バー"の表示がデフォルトで使用されます．それは，回収の状態を表示する
     ためASCIIのプログレスバー表示(a.k.a"温度計の表示")を描画します．
     出力がTTYではない場合，"ドット"のバーがデフォルトで使用されます．

     "ドット"表示に切替えるためには`--progress=dot'を使用してくださ
     い．それは，画面上にドットを出力することで回収を追跡し，それぞれのドッ
     トはダウンロードされたデータの固定量を表現しています．

     ドットでの回収を使用している時，`dot:STYLE'のような形式で
     "スタイル"を指定することもできます．異なるスタイルは一つのドットに
     異なる意味を割り当てます．`default'スタイルでは，それぞれのドット
     は1Kを表現し，1クラスタに10ドットがあり，一行に50ドットあります．
     `binary'スタイルでは，より"コンピュータ"ライクの方針になってい
     ます--ドットは8K，クラスタは16ドット，そして一行は48ドットになります
     (一行が384Kです)．`mega'スタイルは非常に大きなファイルのダウンロー
     ドに適しています--それぞれのドットは64Kの回収を表現していて，1クラス
     タに8ドットあり，それぞれの行には48ドットになります(そのため，それぞれ
     の行は3M含まれています)．

     `.wgetrc'の`progress'コマンドで，デフォルトの形式を設定する
     ことが可能であることに注意して下さい．その設定は，コマンドラインで上書
     きされるかもしれません．例外として，出力がTTYではないとき，"ドット"
     のプログレスバーが"バー"に優先されます．バーの表示を強制したい場合は
     `--progress=bar:force'を使用してください．

`-N'
`--timestamping'
     タイムスタンプを開始します．詳細は，*Note Time-Stamping::.

`-S'
`--server-response'
     HTTPサーバが送るヘッダを出力したり，FTPサーバに返事を送った
     りします．

`--spider'
     このオプションで呼び出された場合，Wgetはウェブ"スパイダー"として動
     作し，それにはページをダウンロードせずに存在を調査するという意味があり
     ます．例えば，ブックマークの調査にWgetを使用することが可能です．

          wget --spider --force-html -i bookmarks.html

     この機能には，Wgetを真のウェブスパイダーの能力に近づけるため，非常に多
     くの仕事がさらに必要です．

`-T seconds'
`--timeout=SECONDS'
     ネットワークのタイムアウトをSECONDS秒に設定します．これは，
     `--dns-timeout'，`--connect-timeout'，そして
     `--read-timeout'を同時に指定することと同じです．

     Wgetがリモートホストに接続する，またはそこから読み出すとき，タイムアウ
     トを調査し，時間が超過した場合は処理を中止します．これで，中途半端な読
     み込みや無限接続といった異常な障害を避けることになります．デフォルトで
     利用可能なタイムアウトは，読み込みのタイムアウトの900秒だけです．タイ
     ムアウトを0に設定することで，タイムアウトの調査を利用不可能にします．

     何を行っているか分からない場合，タイムアウトに関連するオプションを設定
     しないのが最善でしょう．

`--dns-timeout=SECONDS'
     DNSのルックアップタイムアウトをSECONDS秒に設定します．指定された
     時間内に完了しないDNSのルックアップは異常終了になります．デフォルトで
     は，システムライブラリで実装されていない限り，DNSのルックアップにタイ
     ムアウトは存在しません．

`--connect-timeout=SECONDS'
     接続タイムアウトをSECONDS秒に設定します．確立に時間がかかるTCP接
     続は中止されます．デフォルトでは，システムライブラリで実装されていない
     限り，接続タイムアウトは存在しません．

`--read-timeout=SECONDS'
     読み込み(と書き出し)のタイムアウトをSECONDS秒に設定します．時間
     がかかる読み込みは異常終了します．読み込みタイムアウトのデフォルト値は
     900秒です．

`--limit-rate=AMOUNT'
     ダウンロードの速度をAMOUNTバイト毎秒に制限します．AMOUNTは
     バイト表現に，`k'の接尾子を付けたキロバイトや，`m'の接尾子を
     付けたメガバイトでもかまいません．例えば，`--limit-rate=20k'で回
     収のレートを20KB/sに制限します．何らかの理由があって，Wgetが利用可能な
     帯域を全部使用して欲しくないとき，このようなことが役に立ちます．

     Wgetは，指定したレート以上の時間をかけないよう，ネットワークの読み込み
     後に適切な時間スリープすることで制限を実装していることに注意して下さい．
     結局こうすることで，TCPの転送を指定したレートにだいたい落ち着きます．
     しかし，このバランスを達成するまで時間がかかるかもしれないので，制限さ
     れたレートが非常に小さなファイルでうまく動作しない場合でも驚かないでく
     ださい．

`-w SECONDS'
`--wait=SECONDS'
     回収の間に指定した秒数待ちます．要求の生成を少なくすることでサーバの負
     荷を軽くするので，このオプションの使用を推奨します．秒の代わりに時間を
     `m'で後置した分，`h'を後置した時間，`d'を後置した一日で
     指定可能です．

     このオプションに大きな値を指定すると，ネットワークや接続先のホストが落
     ちた場合，Wgetは再試行する前にネットワークエラーの修復が期待される程度
     の妥当な時間待つことができるので役に立ちます．

`--waitretry=SECONDS'
     _すべての_回収の間ではなく，ダウンロードに失敗したときのみWgetを
     待たせたい場合，このオプションを使用することが可能です．Wgetは
     "linear backoff"を使用していて，与えられたファイルでの最初の失敗の
     後に一秒待ち，そのファイルで二番目に失敗した後に二秒待つようにして，指
     定された最大SECONDSまで増加するようになっています．このため，10
     の値は，(1 + 2 + ... + 10) = 55
     秒まで，Wgetは一つのファイルにつき実際 に待つことになります．

     このオプションは，大域的な`wgetrc'ファイルでデフォルトで開始して
     いることに注意してください．

`--random-wait'
     ウェブサイトによっては，Wgetのような回収プログラムを識別するために，要
     求と要求の間の時間による統計的に重要な類似を検索するため，ログ解析を実
     行する可能性があります．このオプションは，`--wait'オプションを使
     用して指定したWAITを用いて，0から2の間にWAIT秒を掛けて変化
     させ，要求と要求の間の時間を変動させ，そのような解析からWgetの存在を隠
     すようになっています．

     有名なコンシュマープラットフォームでの開発に捧げられている出版物の最近
     の論文では，大至急これを解析するコードを提供しています．その著者は，自
     動的な回収プログラムでDHCPで提供するアドレスを悪意を持って変更するもの
     をブロックすることを確実にするため，クラスCのアドレスレベルをブロック
     することを提案しています．

     `--random-wait'オプションは，その動作を行なうウェブサイトから多く
     の無関係なユーザをブロックするような無差別な推奨があることを示唆してい
     ます．

`-Y on/off'
`--proxy=on/off'
     プロキシサポートを開始または停止します．適切な環境変数が定義されている
     場合，プロキシはデフォルトです．

     Wgetでプロキシを使用する際の詳細は，*Note Proxies::.

`-Q QUOTA'
`--quota=QUOTA'
     自動回収に対するダウンロードクォータを指定します．値は(デフォルトで)バ
     イト，(`k'の後置で)キロバイト，(`m'の後置で)メガバイトで指定
     可能です．

     クォータは単一ファイルのダウンロードで効果が無いことに注意してください．
     そのため，`wget -Q10k ftp://wuarchive.wustl.edu/ls-lR.gz'のように
     指定した場合，`ls-lR.gz'全体がダウンロードされます．複数の
     URLがコマンドラインで指定されたときも，同様なことが生じます．しか
     し，回収が再帰的なときや入力ファイルからのときにクォータは尊重されます．
     このため，安全に`wget -Q2m -i sites'と入力ことができます--ダウン
     ロードはクォータ以上になったとき中止します．

     クォータを0や`inf'に設定すると，ダウンロードクォータは無制限にな
     ります．

`--dns-cache=off'
     DNSルックアップのキャッシュを停止します．通常，WgetはDNSから検索したア
     ドレスを記憶しているので，回収している同じアドレス群(通常は小さい)に対
     してDNSサーバに何度も問い合わせる必要はありません．このキャッシュは，
     メモリだけに存在します．新たにWgetを実行すると，再びDNSに問い合わせし
     ます．

     しかし，場合によってはホスト名のキャッシュに価値が無いこともあり，それ
     は，Wgetのようなちょっとしたアプリケーションの実行の間でもそうです．例
     えば，HTTPサーバには，刻々と変化する動的なIPアドレスを割り当てを利用し
     てホスティングしているものもあります．それらのDNSのエントリーは変化す
     るたびに更新されます．Wgetによるそれぞれのホストからのダウンロードで，
     IPアドレスの変更が判別したとき，Wgetはダウンロードを再試行しますが，
     (DNSキャッシュのため)古いアドレスに接続してしまいます．DNSキャッシュを
     停止することで，Wgetは接続するたびにDNSルックアップを繰返し，そのため
     正しい動的なアドレスを毎回入手します--余分なDNSルックアップのコストは
     おそらく不要なものなんですけど．

     上記の記述を理解していない場合，おそらくこのオプションは不要でしょう．

`--restrict-file-names=MODE'
     リモートのURLで見つかった文字で，そのURLから生成されるローカルファイル
     名が存在する可能性がある文字を変更します．このオプションで"制限さ
     れる(restricted)"文字はエスケープされます．すなわち，`%HH'で置換
     され，`HH'は制限された文字に対応する16進数です．

     デフォルトで，通常は出力不可能な制御文字同様，オペレーティングシステム
     上のファイル名の一部として有効ではない文字を，Wgetはエスケープします．
     このオプションは，ネイティブなパーティションではないところにダウンロー
     ドしたり，制御文字のエスケープを利用不可能にしたいなどの理由で，これら
     のデフォルトを変更するときに役に立ちます．

     モードが"unix"に設定されているとき，Wgetは，文字`/'と0-31の範
     囲と128-159の範囲の制御文字をエスケープします．これはUnixに似たOS上で
     のデフォルトです．

     モードが"windows"に設定されているとき，Wgetは，文字`\'，
     `|'，`/'，`:'，`?'，`"'，`*'，`<'，
     `>'と0-31の範囲と128-159の範囲の制御文字をエスケープします．こ
     れに加え，windowsモードでのWgetは，ローカルファイル名でのホストとポー
     トの分離に`:'の代わりに`+'を使用し，残りのファイル名のクエリ
     部分の分離に`?'の代わりに`@'を使用します．このため，unixモー
     ドで`www.xemacs.org:4300/search.pl?input=blah'として保存されるURL
     はwindowsモードでは`www.xemacs.org+4300/search.pl@input=blah'と
     して保存されます．このモードはWindowsではデフォルトです．

     `unix,nocontrol'のように，モードに`,nocontrol'を追加した場合，
     制御文字のエスケープも停止します．ファイル名の制限モードとして使用する
     OSの選択に影響を与えないまま，制御文字のエスケープを停止するために，
     `--restrict-file-names=nocontrol'を使用することが可能です．


File: wget-ja.info,  Node: Directory Options,  Next: HTTP Options,  Prev: Download Options,  Up: Invoking

ディレクトリオプション
======================

`-nd'
`--no-directories'
     再帰的に回収するときにディレクトリの階層を作成しません．このオプション
     を開始すると，全てのファイルは現在のディレクトリに上書き無しで保存され
     ます(名前が一度以上現れる場合，ファイル名は拡張子`.n'が付きます)．

`-x'
`--force-directories'
     `-nd'の反対です--階層無しで作成されていても，ディレクトリ階層を
     作成します．例えば，`wget -x http://fly.srk.fer.hr/robots.txt'は
     ファイルを`fly.srk.fer.hr/robots.txt'にダウンロードします．

`-nH'
`--no-host-directories'
     ホストを前置したディレクトリの生成を不可にします．デフォルトで，Wgetを
     `-r http://fly.srk.fer.hr/'を用いて呼び出した場合，
     `fly.srk.fer.hr/'で始まるディレクトリ構造を作成します．このオプショ
     ンはそのような動作を不可にします．

`--cut-dirs=NUMBER'
     ディレクトリコンポーネントのNUMBERを無視します．再帰的回収で保存
     されたディレクトリ上の，きめ細かい制御でこれは役に立ちます．

     例えば，`ftp://ftp.xemacs.org/pub/xemacs/'ディレクトリの取得する
     とします．`-r'で回収した場合，`ftp.xemacs.org/pub/xemacs/'以
     下にローカル保存されます．一方，`-nH'オプションは
     `ftp.xemacs.org/'の部分を削除し，`pub/xemacs'で保存します．
     これが`--cut-dirs'が役に立つところです．それで，Wgetはリモートディ
     レクトリコンポーネントのNUMBER(数)を"見"ないようなります．
     `--cut-dirs'オプションがどのように動作するかを示す例は以下のよう
     になります．

          No options        -> ftp.xemacs.org/pub/xemacs/
          -nH               -> pub/xemacs/
          -nH --cut-dirs=1  -> xemacs/
          -nH --cut-dirs=2  -> .
          
          --cut-dirs=1      -> ftp.xemacs.org/xemacs/
          ...

     ディレクトリ構造を取り除きたいだけの場合，このオプションは`-nd'と
     `-P'の組合せに似ています．しかし，`-nd'とは異なり，
     `--cut-dirs'はサブディレクトリを失いません--例えば，`-nH
     --cut-dirs=1'を用いた場合，`beta/'サブディレクトリは，期待通りに
     `xemacs/beta'に配置されます．

`-P PREFIX'
`--directory-prefix=PREFIX'
     ディレクトリプレフィクスをPREFIXに設定します．"ディレクトリ
     プレフィクス"は，他の全てのファイルとサブディレクトリが保存されるディ
     レクトリで，すなわち回収ツリーのトップになります．デフォルトは
     `.'(カレントディレクトリ)です．


File: wget-ja.info,  Node: HTTP Options,  Next: FTP Options,  Prev: Directory Options,  Up: Invoking

HTTPオプション
==============

`-E'
`--html-extension'
     `application/xhtml+xml'や`text/html'形式のファイルがダウンロー
     ドされ，URLが正規表現の`\.[Hh][Tt][Mm][Ll]?'で終わらない場合，こ
     のオプションは接尾子`.html'をローカルのファイル名に後置します．例
     えば，`.asp'ページを使用したリモートサイトをミラーし，手元のApach
     サーバで閲覧可能なミラーにしたい場合，これは役に立ちます．もう一つのこ
     の優れた利用方法は，CGIが生成したものをダウンロードするときです．
     `http://site.com/article.cgi?25'のようなURLは，
     `article.cgi?25.html'として保存されます．

     この方法で変更されたファイル名は，Wgetはローカルの`X.html'
     ファイルとリモートのURL `X'と一致するかどうか分からないため
     (それは，URLが生成する`text/html'形式や
     `application/xhtml+xml'形式の出力が分からないためです．)，再びダ
     ウンロードするたびにサイトをミラーリングすることに注意してください．こ
     の再ダウンロードを避けるため，ファイルのオリジナルバージョンが
     `X.orig'として保存されるように，`-k'と`-K'を使用
     する必要があります(*note Recursive Retrieval Options::)．

`--http-user=USER'
`--http-passwd=PASSWORD'
     HTTPサーバでのユーザ名をUSERに，そしてパスワードを
     PASSWORDに指定します．試みる形式によって，Wgetは`basic' (安
     全でない)，または`digest'認証手法のいずれかを用いて符号化します．

     もう一つの方法は，ユーザ名とパスワードをURL自身に書く方法です
     (*note URL Format::)．いずれの手法でも，`ps'を実行することで，パ
     スワードがばれてしまいます．パスワードが見えないようにするため．それら
     を`.wgetrc'や`.netrc'に保存し，それらのファイルを
     `chmod'を使用して他のユーザから確実に保護してください．パスワード
     が本当に重要な場合，それらのファイルにも残さないようにして下さい--ファ
     イルを編集し，Wgetがダウンロードを開始した後で削除して下さい．

     Wgetのセキュリティーの問題に関する詳細は，*Note Security
     Considerations::.

`-C on/off'
`--cache=on/off'
     オフに設定したときサーバサイドのキャッシュを不可にします．この場合Wget
     は，リモートサービスからファイルを得るため，キャッシュバージョンを返す
     代わりにリモートサーバに適切なディレクティブ(`Pragma: no-cache')
     を送ります．これは，プロキシサーバの時代遅れのドキュメントを回収し，ク
     リアするときに特に役立ちます．

     キャッシュはデフォルトで可能になっています．

`--cookies=on/off'
     オフに設定するとき，クッキーは使用不可能になります．クッキーはサーバ側
     の状態を管理するメカニズムです．サーバは`Set-Cookie'ヘッダを使用
     してクライアントにクッキーを送り，クライアントはそれ以降の要求で同じクッ
     キーを使用して応答します．クッキーはサーバの所有者が訪問者の追跡を保存
     し，サイトがこの情報を交換することを可能にするので，それらをプライバシー
     の侵害と考える人もいます．デフォルトはクッキーの使用です．しかし，クッ
     キーの_保存_はデフォルトではありません．

`--load-cookies FILE'
     最初のHTTPの回収の前にFILEからクッキーをロードします．FILE
     の書式は，少なくともUnixバージョンのNetscapeとMozillaで使用されている
     ものです．

     サイトの内容にアクセスするためにログインすることを要求するサイトをミラー
     リングする時，通常，このオプションを使用します．ログインのプロセスは，
     通常，ウェブサーバがHTTPクッキーを発行し，回収し，証明書を検証す
     ることで動作します．クッキーは，サイトの一部にアクセスしたときブラウザ
     が再送信し，個人識別情報を提供します．

     サイトのミラーリングで，サイトと通信する時にウェブブラウザが送るものと
     同じクッキーをWgetに送るよう要求します．これは，`--load-cookies'
     で達成されます--単純にWgetに`cookies.txt'ファイルがある場所を示
     し，そうすることでブラウザが同じ状況で送るものと同じクッキーを送ります．
     異なるブラウザはテキストのクッキーファイルを異なる場所に保存します．

    Netscape 4.x.
          クッキーは`~/.netscape/cookies.txt'になります．

    Mozilla and Netscape 6.x.
          Mozillaのクッキーファイルも`cookies.txt'という名前で，プロファイ
          ルのディレクトリの`~/.mozilla'の下のどこかにあります．フルパスは
          `~/.mozilla/default/SOME-WEIRD-STRING/cookies.txt'のような
          場所で見つかります．

    Internet Explorer.
          ファイルメニューの，インポートとエクスポートの，エクスポートクッキーを
          使用することで，Wgetが使用可能なクッキーファイルを生成可能です．これは，
          Internet Explorer
          5でテストしました．それより前のバージョンでの動作は
          保証しません．

    その他のブラウザ
          クッキーを作成したものと異なるブラウザを使用している場合，場所を指定可
          能，またはWgetが期待するNetscapeのフォーマットのクッキーファイルを生成
          することが可能な場合のみ動作します．

     `--load-cookies'が使用不可能な場合，代替方法もあります．ブラウザ
     が"クッキーマネージャ"をサポートしている場合，ミラーしているサイトに
     アクセスする時，使用されているクッキーを見るためにそれを使用することが
     可能です．名前とクッキー名を書き下ろし，手動でこれらのクッキーを送るよ
     うWgetに命令し，"公式の"クッキーサポートを回避してください．

          wget --cookies=off --header "Cookie: NAME=VALUE"

`--save-cookies FILE'
     セッションの終りにFILEにクッキーを保存します．破棄する時間が指定
     されていないクッキーや，既に期限切れのクッキーは保存されません．

`--ignore-length'
     残念ながら，HTTPサーバ(より正確にはCGIプログラム)には，偽の
     `Content-Length'ヘッダを送るものもあり，それではドキュメント全て
     が回収されないので，Wgetがおかしくなります．Wgetが同じドキュメントを何
     度も何度も回収し，そのたびに(通常でない)接続が同じバイト数で閉じている
     報告を得る場合，この症状を見付けることが可能です．

     このオプションを用いた場合，Wgetは`Content-Length'ヘッダを--まる
     で存在しないかのように--無視します．

`--header=ADDITIONAL-HEADER'
     HTTPに渡すADDITIONAL-HEADERを定義します．ヘッダは，一つ以上
     の空白ではない文字が前置されている`:'を含んでいて，それには改行を
     含めてはなりません．

     一つ以上の追加ヘッダを，一度以上`--header'を指定することで定義し
     てもかまいません．

          wget --header='Accept-Charset: iso-8859-2' \
               --header='Accept-Language: hr'        \
                 http://fly.srk.fer.hr/

     ヘッダ値として空の文字列を指定すると，以前ユーザが定義した全てのヘッダ
     をクリアします．

`--proxy-user=USER'
`--proxy-passwd=PASSWORD'
     プロキシサーバの認証のため，ユーザ名USERとパスワード
     PASSWORDを指定します．Wgetはこれらを`basic'認証手法で符号化
     します．

     セキュリティへ考慮は，`--http-passwd'に関連するものによく似ていま
     す．

`--referer=URL'
     HTTPの要求に`Referer: URL'ヘッダを含めます．常に対話的なウェブブ
     ラウザでの回収を期待していて，Refererがそれを示すページの一つに設定さ
     れているときのみ正しく出力するサーバサイドプロセスを用いたドキュメント
     の回収で役に立ちます．

`-s'
`--save-headers'
     HTTPサーバがファイルにつけて送ったヘッダを空白行で分けて，実際の
     内容の前につけて保存します．

`-U AGENT-STRING'
`--user-agent=AGENT-STRING'
     AGENT-STRINGとしてHTTPサーバを識別します．

     HTTPプロトコルは，クライアントが`User-Agent'ヘッダフィールド
     を用いた自分自身の識別を許可しています．これでWWWソフトウェアの区
     別が可能となり，通常のプロトコル違反の追跡目的には十分です．Wgetは通常
     `Wget/VERSION'として識別され，VERSIONはWgetの現在のバー
     ジョンナンバーです．

     しかし，サイトによっては`User-Agent'が供給する情報によって出力を
     調整するポリシーを課すことが知られています．概念的には，これはそんなに
     悪い考えではないのですが，`Mozilla'やMicrosoft `Internet
     Explorer'以外のクライアントに情報の提供を拒否するように乱用されてもい
     ました．このオプションで，Wgetが発行する`User-Agent'を変更できま
     す．このオプションの使用は，行っていることを本当に知らない場合は思い留
     まってください．

`--post-data=STRING'
`--post-file=FILE'
     すべてのHTTPリクエストと，リクエストの本文に指定されたデータを送信する
     手段としてPOSTを使用します．`--post-data'はSTRINGをデータと
     して送信し，`--post-file'はFILEの内容を送信します．それ以外
     では，同じように動作します．

     Wgetは，POSTするデータの大きさを前もって知っておく必要があることに注意
     して下さい．このため，`--post-file'の引数は通常のファイルにする必
     要があります．FIFOや`/dev/stdin'のようなものを指定すると動作しま
     せん．HTTP/1.0に起因するこの制限を，回避する方法は全く分かりません．
     HTTP/1.1ではリクエストの長さを前もって知る必要が無い"chunked"転送
     が導入されましたが，クライアントはHTTP/1.1サーバと通信していることが分
     かるまで，chunkedを使用することはできません．また，レスポンスを受信す
     るまでそれは分からないので，完了するまでリクエストを順次送信する必要が
     あります-鶏と卵の問題です．

     注意：POSTリクエストが完了した後に，Wgetがリダイレクトされる場合，POST
     データをリダイレクトされたURLに送信しません．これは，POSTを処理するURL
     が通常のページにリダイレクトを用いて応答するためで(技術的に利用不可能
     ですが)，それはPOSTを要求したり受け入れたりしません．このオプションの
     動作はまだ明確ではありません．うまく動作しなければ変更します．

     以下の例は，POSTを使用しているサーバのログをとらせ，要求されている，お
     そらく認証されたユーザだけがアクセス可能なページをダウンロードを行なう
     方法を示します．

          # Log in to the server.  This can be done only once.
          wget --save-cookies cookies.txt \
               --post-data 'user=foo&password=bar' \
               http://server.com/auth.php
          
          # Now grab the page or pages we care about.
          wget --load-cookies cookies.txt \
               -p http://server.com/interesting/article.php


File: wget-ja.info,  Node: FTP Options,  Next: Recursive Retrieval Options,  Prev: HTTP Options,  Up: Invoking

FTPオプション
=============

`-nr'
`--dont-remove-listing'
     FTPの回収で生成された，一時的な`.listing'を削除しません．通
     常，これらのフィルは，FTPサーバから得た生のディレクトリリストを含
     んでいます．それを削除しないことで，デバッグが目的のときや，リモートサー
     バのディレクトリの内容について簡単な調査を可能にしたい時に役に立つはず
     です(例えば，実行しているミラーが完全なことを検証します)．

     Wgetが既知のファイル名にこのファイルを書いたとしても，ユーザが
     `.listing'のシンボリックリンクを`/etc/passwd'に作成したり，
     `root'にWgetをそのホームディレクトリで実行するように頼むといった
     シナリオでも，これはセキュリティホールにはならないことに注意してくださ
     い．使用するオプションに依存して，Wgetは`.listing'への書き込みを
     拒否したり，glob/再帰/タイムスタンプの処理を失敗させたり，シンボリック
     リンクが削除されたり実際の`.listing'ファイルに置換されたり，リス
     トが`.listing.NUMBER'ファイルに書き込まれたりします．

     この状況に問題があっても，`root'は決してWgetを信頼できないユーザ
     のディレクトリで実行しません．ユーザは`index.html'を
     `/etc/passwd'にリンクしたり，ファイルが上書きされるように
     `root'に`-N'や`-r'を用いてWgetを実行するように頼むよう
     な，簡単なことしかできません．

`-g on/off'
`--glob=on/off'
     FTPのglobをオン/オフします．globはシェルのような特別文字("ワ
     イルドカード(wildcards)")を意味し，同じディレクトリから一度に一つ以上
     のファイルを回収するための`*'，`?'，`['と`]'のよう
     なもので，以下のようにします．

          wget ftp://gnjilux.srk.fer.hr/*.msg

     デフォルトで，URLがglob文字を含む場合，globはオンです．このオプショ
     ンで永久的にglobのオン/オフに使用できます．

     シェルによる展開から保護するため，URLを引用符で囲む必要があるかも
     しれません．globでWgetにディレクトリリストを探し，それはシステム指定の
     ものになっています．これは，現在の仕事がFTPサーバでのみ動作するか
     らです(そしてそれは，Unix `ls'出力をエミュレートします)．

`--passive-ftp'
     "passive" FTP回収手法を使用し，そこでクライアントはデータ接続
     を開始します．これは，FTPをファイアーウォールの後ろから動作させる
     ため，必要なときもあります．

`--retr-symlinks'
     通常，FTPディレクトリを再帰的にダウンロードしていて，シンボリック
     リンクに遭遇したとき，リンクされているファイルはダウンロードされません．
     その代わりに，マッチしたシンボリックリンクはローカルファイルシステムに
     作成されます．指し示されているファイルは，この再帰的な回収でバラバラに
     なり，それを何とかしてダウンロードしようとしない限り，ダウンロードされ
     ません．

     しかし，`--retr-symlinks'が指定されている場合，シンボリックリンク
     は切断され，指定されたファイルが回収されます．この時，このオプションで，
     Wgetはディレクトリに対するシンボリックリンクを切断して再帰的に回収しま
     せんが，将来はそうするように拡張されるでしょう．

     ファイル(ディレクトリではない)の回収時には，それが再帰されているためで
     はなく，それがコマンドラインで指定されているために，このオプションの効
     果がなくなります．シンボリックリンクは，この場合は常に切断されます．


File: wget-ja.info,  Node: Recursive Retrieval Options,  Next: Recursive Accept/Reject Options,  Prev: FTP Options,  Up: Invoking

再帰的な回収オプション
======================

`-r'
`--recursive'
     再帰的な回収を開始します．詳細は*Note Recursive Retrieval::.

`-l DEPTH'
`--level=DEPTH'
     再帰的な最大深度の階層をDEPTHに設定します．(*note Recursive
     Retrieval::)．デフォルト最大深度は5です．

`--delete-after'
     このオプションは，ダウンロードした_後_に全ての単一ファイルを削除
     するようWgetに伝えます．それはプロキシから取得した一般的なページに対し
     便利で，例えば以下のようにします．

          wget -r -nd --delete-after http://whatever.com/~popular/page/

     `-r'オプションは再帰的に回収し，`-nd'はディレクトリを作成し
     ません．

     `--delete-after'がローカルマシンのファイルを削除することに注意し
     てください．例えばそれは，リモートのFTPサイトに`DELE'コマンドを発
     行しません．また`--delete-after'が指定されたとき，`.orig'ファ
     イルが単純に最初の位置に作成されないため，`--convert-links'が無視
     されることにも注意してください．

`-k'
`--convert-links'
     ダウンロードが完了した後，ドキュメント内のリンクをローカルでの閲覧に適
     したものに変換します．これは目に見えるハイパーリンクのみならず，埋め込
     み画像，スタイルシートへのリンク，HTMLでない内容へのハイパーリン
     ク等のように，外部の内容にリンクしているドキュメントの，あらゆる部分に
     も影響があります．

     それぞれのリンクは二つの方法のうちの一つで変換されます．

        *
          Wgetでダウンロードされたファイルへのリンクは，相対的なリンクとしてそれ
          が示すファイルへの参照を変更します．

          例：ダウンロードされたファイル`/foo/doc.html'が
          `/bar/img.gif'にリンクしていて，それもダウンロードされている場合，
          `doc.html'内のリンクは`../bar/img.gif'を示すものに変更されま
          す．この種の変換は，ディレクトリの任意の組合せで信頼できるように動作し
          ます．

        *
          Wgetがダウンロードしていないファイルへのリンクは，ホスト名とそれが示す
          場所の絶対パスに変更されます．

          例：ダウンロードされたファイル`/foo/doc.html'が，
          `/bar/img.gif' (または`../bar/img.gif')へリンクしている場合，
          `doc.html'内のリンクは`http://HOSTNAME/bar/img.gif'を
          示すものに変更されます．

     このため，ローカルでの閲覧が信頼できるように動作します．リンクされてい
     るファイルがダウンロードされている場合，リンクはそのローカル名を参照し
     ます．それがダウンロードされていない場合は，リンクは存在する壊れたリン
     クではなく，その完全なインターネットアドレスを参照します．前のリンクが
     相対リンクに変換されるという事実は，ダウンロードされた階層を別のものに
     移動することを確実に可能にします．

     ダウンロード後のみ，Wgetはリンクがダウンロードされたことを知ることがで
     きます．そのため，`-k'が行う仕事は，すべてのダウンロード終りに実
     行されます．

`-K'
`--backup-converted'
     ファイルの変換時に，オリジナルバージョンのファイルを`.orig'接尾子
     を用いてバックアップします．`-N'の動作に効果があります (*note HTTP
     Time-Stamping Internals::)．

`-m'
`--mirror'
     ミラーに適したオプションを開始します．このオプションは回収とタイムスタ
     ンプを開始し，無限の再帰深度を設定し，FTPディレクトリリストを保ち
     ます．現在は，`-r -N -l inf -nr'と同じです．

`-p'
`--page-requisites'
     このオプションで，Wgetは与えられたHTMLページを適切に表示するのに
     必要なすべてのファイルをダウンロードします．これは，画像，音声，そして
     参照されるスタイルシートのようなものを含みます．

     通常は，単一のHTMLページをダウンロードするとき，正しく表示するの
     に要求される可能性のある，必要なドキュメントも全くダウンロードされませ
     ん．`-l'を用いた`-r'オプションの使用は役に立つはずですが，
     Wgetは外部とインラインドキュメントを通常区別するので，通常は失われた必
     要なものとなる"leaf documents"として残ったままです．

     例えば，`1.gif'を参照する`<IMG>'タグと，外部ドキュメント
     `2.html'を指し示す`<A>'タグを含む，ドキュメントを考えます．
     `2.html'は似ていますが，その画像`2.gif'でそのリンクは
     `3.html'とします．この繰り返しは，任意の，より大きい数字まである
     とします．

     以下のコマンドを実行したとします．

          wget -r -l 2 http://SITE/1.html

     すると，`1.html'，`1.gif'，`2.html'，`2.gif'，そし
     て`3.html'はダウンロードされます．見てお分かりのように，再帰を停
     止する場所を決定するために，Wgetは，`1.html'からのホップの数(を2
     まで) しか数えないので，`3.html'にはそれが必要とする`3.gif'
     がありません．しかし，以下のコマンドを用いたとします．

          wget -r -l 2 -p http://SITE/1.html

     それは，上記のすべてのファイル_および_`3.html'が必要とする
     `3.gif'がダウンロードされます．同様に，以下のようにします．

          wget -r -l 1 -p http://SITE/1.html

     これで，`1.html'，`1.gif'，`2.html'，そして`2.gif'
     がダウンロードされます．このように考えることもできます．

          wget -r -l 0 -p http://SITE/1.html

     これは，`1.html'と`1.gif'のみをダウンロードすると思われます
     が，`-l 0'は`-l inf'--すなわち無限再帰--と等価なので，残念
     ながらそうなりません．単一のHTMLページ(または，コマンドラインや
     `-i' URL入力ファイルで指定された少数のもの)とその(またはそれ
     らの)必需品をダウンロードするために，単に`-p'と`-l'のみ残し
     てください．

          wget -p http://SITE/1.html

     Wgetは，`-r'が指定されたかのように動作しますが，単一のページとそ
     の必需品のみダウンロードされることに注意してください．外部ドキュメント
     へのリンクはだとりません．実際，単一のページとその必需品を(たとえ別の
     ウェブサイトに存在していても)ダウンロードするためと，ひとまとまりで正
     しくローカルに表示することを保証するために，この作者は，`-p'に加
     えていくつかのオプションを使用することを好みます．

          wget -E -H -k -K -p http://SITE/DOCUMENT

     このトピックの終りになりますが，外部ドキュメントへのリンクだとWgetが考
     える方法は，`<A>'タグ，`<AREA>'タグ，または，`<LINK
     REL="stylesheet">'以外の`<LINK>'タグで指定されているあらゆるURLが
     そうであると考えるという方法です．

`--strict-comments'
     HTMLのコメントの厳密な字句解析を開始します．デフォルトは，最初に
     `-->'が見つかったときにコメントを終了します．

     仕様書によると，HTMLのコメントは，SGMLの"宣言
     (declarations)"として表現されています．宣言は`<!'で始まり`>'
     で終る`<!DOCTYPE ...>'のような特別なマークアップで，それには
     `--'分離子の組の間にコメントを含めてもかまいません．HTMLのコ
     メントは"'空の宣言"で，それはコメントのテキストが無いSGMLの宣言
     です．このため，`<!--foo-->'は有効なコメントで，`<!--one--
     --two-->'もそうですが，`<!--1--2-->'はそうではありません．

     一方，ほとんどのHTML作者は，コメントの理解として`<!--'と
     `-->'で分離されたテキストとして以上のものはなく，それは同じもので
     はありません．例えば，`<!------------>'のようなものはダッシュの数
     が四の倍数になっている限り有効なコメントとして動作します(!)．そうでな
     い場合，コメントは技術的には，次の`--'がない限り最後まで続き，そ
     れはドキュメントの最後まで行ってしまうかもしれません．このため，多くの
     有名なブラウザは，仕様書を無視し，ユーザが期待したように実装されていま
     す．コメントは`<!--'と`-->'で分離されています．

     バージョン1.9までのWgetはコメントを厳密に解釈していて，結果として多く
     の洗練されているブラウザでは表示される，多くのWebページへのリンクが失
     われていて，準拠していないコメントを含むものが不幸にも残っていました．
     バージョン1.9からは，"ネイティブ"のコメント，つまりそれぞれのコメン
     トは最初に`-->'が見つかると終端されたものとして実装されたクライア
     ントの仲間入りを成し遂げました．

     何らかの理由があって，厳密なコメントとする字句解析を行ないたい場合，こ
     のオプションを使用して，それを開始して下さい．


File: wget-ja.info,  Node: Recursive Accept/Reject Options,  Prev: Recursive Retrieval Options,  Up: Invoking

再帰の受け入れ/拒絶オプション
=============================

`-A ACCLIST --accept ACCLIST'
`-R REJLIST --reject REJLIST'
     受け入れるまたは拒絶する，カンマで分けられたファイル名の接尾子やパター
     ンを指定します(詳細は，*note Types of Files::)．

`-D DOMAIN-LIST'
`--domains=DOMAIN-LIST'
     (リンクを)たどるドメインを設定します．DOMAIN-LISTはカンマで分け
     られたドメインのリストです．`-H'を開始しないことに注意してくださ
     い．

`--exclude-domains DOMAIN-LIST'
     (リンクを)たどら_ない_ドメインを指定します．(*note Spanning
     Hosts::)．

`--follow-ftp'
     HTMLドキュメントからのFTPリンクをたどります．このオプション
     が無い場合，Wgetは全てのFTPリンクを無視します．

`--follow-tags=LIST'
     再帰的な回収でリンクされているドキュメントを探すとき，HTMLタグ /
     の属性の対になると考えられるの内部テーブルを持っています．しかし，ユー
     ザが考慮すべきタグのサブセットのみ欲しい場合，このオプションとともに，
     カンマで分けられているLIST内のタグを指定すべきです．

`-G LIST'
`--ignore-tags=LIST'
     これは，`--follow-tags'オプションの反対です．ダウンロードするドキュ
     メントを再帰的に探すとき，特定のHTMLタグをスキップするため，カン
     マで分けられたLIST内で指定してください．

     以前は，`-G'オプションは，単一のページとその必要物をダウンロード
     するとき最善の策で，それは以下のようなコマンドラインになりました．

          wget -Ga,area -H -k -K -r http://SITE/DOCUMENT

     しかし，このオプションの作者は，`<LINK REL="home" HREF="/">'のよ
     うなタグを用いたページに出会い，`-G'が現実的ではないことを実感し
     ました．スタイルシートがダウンロードされないため，Wgetに`<LINK>'
     を無視させるように伝えることができませんでした．現在は，単一のページと
     その必要物をダウンロードする最善の策は，`--page-requisites'オプショ
     ンを掲げています．

`-H'
`--span-hosts'
     再帰的な回収時に，ホストにまたることを可能とします(*note Spanning
     Hosts::)．

`-L'
`--relative'
     相対リンクのみたどります．同じホストからでも気にしないで，特定のホーム
     ページを回収することに役立ちます(*note Relative Links::)．

`-I LIST'
`--include-directories=LIST'
     ダウンロード時に，(リンクを)だどりたいディレクトリのカンマで分けられた
     リストを指定します(詳細は，*note Directory-Based Limits::)．LIST
     の要素にはワイルドカードを含めることができます．

`-X LIST'
`--exclude-directories=LIST'
     ダウンロードから削除したいディレクトリの，カンマで分けられたリストを指
     定します(詳細は，*note Directory-Based Limits::)．LISTの要素はワ
     イルドカードを含めることができます．

`-np'

`--no-parent'
     再帰的な回収時に親ディレクトリへ登りません．特定の階層_以下の_ファ
     イルのみダウンロードすることを保証するので，これは便利なオプションです．
     詳細は，*Note Directory-Based Limits::.


File: wget-ja.info,  Node: Recursive Retrieval,  Next: Following Links,  Prev: Invoking,  Up: Top

再帰的な回収
************

   GNU Wgetは，Web(または，単一のHTTPやFTPサーバ)の部分を，リン
クとディレクトリ構造をたどりながら渡り歩くことができます．これは
"再帰的な回収(recursive retrieval) "，または"再帰(recursion)"
と呼ばれます．

   HTTP URLを用いると，Wgetは与えられたURLすなわちドキュメ
ントから得たHTMLを，`href'や`src'のようなマークアップを
通じて，HTMLドキュメントが参照しているファイルを回収しながら，回
収と解析を行ないます．新たにダウンロードされたファイルも
`text/html'形式や`application/xhtml+xml'形式の場合も，それは
解析され更に続けます．

   HTTPの再帰的な回収とHTMLの内容は"breadth-first"です．こ
れは，要求されたHTMLドキュメントをWgetが最初に，その後でドキュメ
ントがリンクしているドキュメントを，そして更にそれがリンクしているドキュ
メントというようにダウンロードすることを意味します．言い替えると，Wget
は最初に深さ1のドキュメントをダウンロードし，それから深さ2のものという
ようにして最大深度で指定されたものまでダウンロードするということです．

   回収が下降する最大の"深度"は，`-l'オプションで指定されます．
デフォルトの最大深度は5階層です．

   FTP URLを再帰的に回収するとき，Wgetはリモートサーバの与えら
れた(指定された深度以上のサブディレクトリを含め)ディレクトリツリーから，
全てのデータを回収し，ローカルにミラーイメージを作成します．FTPの
回収も`depth'パラメータで制限されます．HTTPの再帰と異なり，
FTPの再帰は最初の深度で実行されます．

デフォルトで，Wgetはローカルディレクトリツリーを作成し，それはリモート
サーバで見つかったものに対応しています．

   再帰的回収は複数の応用が可能で，最も重要なものはミラーです．それは，
WWWの公開と，その他の状況として，ネットワーク接続が遅いところでファ
イルをローカルに保存することでバイパスすることで役に立ちます．

再帰呼び出しはネットワークを通じたデータの高速転送になるため，システム
の過負荷を起こす可能性があることを警告します．このため，管理者の多くは
それに難色を示していて，大量の内容物を高速にダウンロードしているのを検
出した場合，あなたのサイトからのアクセスを禁止するかもしれません．
Internetサーバからダウンロードしている時，サーバへのアクセスの間の遅延
を導入するため，`-w'オプションを使用することを考慮に入れてしてく
ださい．ダウンロードにはより長い時間がかかりますが，サーバ管理者はあな
たの無礼には心配しなくなるでしょう．

もちろん，再帰的なダウンロードは自分のマシンにも問題を発生するかもしれ
ません．調査無しで実行したままにする場合，ディスクが簡単にいっぱいにな
るはずです．ローカルのネットワークからのダウンロードの場合，メモリと
CPUの消費と同様に，システムの帯域幅にも注意すべきです．

   ダウンロードを達成するような試みに適した基準を指定してみてください．1
ページのみダウンロードしたい場合，あらゆる再帰を追加すること無く
`--page-requisites'を使用してください．一つのディレクトリ以下をダ
ウンロードしたい場合，他のディレクトリからダウンロードすることを避ける
ため`-np'を使用してください．一つのディレクトリの全てのファイルを
ダウンロードしたい場合，再帰深度が超過しないことを確実にするため `-l
1'を使用してください．これについての詳細は*Note Following Links::.

再帰的な回収は注意して使用すべきです．警告しなかったとは言わせません．


File: wget-ja.info,  Node: Following Links,  Next: Time-Stamping,  Prev: Recursive Retrieval,  Up: Top

リンクの追跡
************

再帰的な回収で不必要なデータの回収になることを望む人はいません．ほとん
どいつも，ダウンロードしたいものとWgetにたどらせたい特定のリンクのみを，
ユーザは正しく覚えています．

   例えば，`fly.srk.fer.hr'から音楽のアーカイブをダウンロードしたい
場合，アーカイブの曖昧な部分の参照から生じる，全てのホームページのダウ
ンロードを望みません．

たどりたいリンクを正確に調整することを可能とする，いくつかのメカニズム
がWgetにはあります．

* Menu:

* Spanning Hosts::         (Un)limiting retrieval based on host name.
* Types of Files::         Getting only certain files.
* Directory-Based Limits:: Getting only certain directories.
* Relative Links::         Follow relative links only.
* FTP Links::              Following FTP links.


File: wget-ja.info,  Node: Spanning Hosts,  Next: Types of Files,  Prev: Following Links,  Up: Following Links

ホストをまたぐ
==============

Wgetの再帰的な回収は，通常はコマンドラインで指定されたものと異なるホス
トを訪れることを拒否します．これはデフォルトで妥当です．そうしない場合，
全ての回収で，Wgetがgoogleの縮小版になり得ます．

   しかし，異なるホストを訪れたり，"ホストをまたぐこと"が役に立つオプ
ションとなる時もあります．画像が異なるサーバから提供されているかもしれ
ません．三つのサーバ間の内部リンクでページ構成されているサイトのミラー
リングしているかもしれません．サーバが二つの等価な名前を持ち，
HTMLページが両方を交替しながら参照しているかもしれません．

あらゆるホストをまたぐ--`-H'
     `-H'オプションはホストをまたぐことを開始し，そのため，リンクで参
     照されている全てのホストを訪れながら，Wgetの再帰的な回収が可能となりま
     す．再帰の制限の基準が適切な深度に指定されていない限り，これらの外部の
     ホストは通常更に多くのホストにリンクされていて，Wgetはあなたが考えてい
     たものより遥かに多くのデータを終りまで吸い上げ続けます．

特定のドメインだけまたぐように制限する--`-D'
     `-D'オプションを用いてたどるドメインを指定でるようになり，そのた
     め，これらのドメインに所属しているホストのみ再帰的に扱うよう制限されま
     す．`-H'と組み合わせることでのみ，明確な意味があります．典型的な
     例として，`images.server.com'からのダウンロードを許可しながら
     `www.server.com'の内容をダウンロードするなどです．

          wget -rH -Dserver.com http://www.server.com/

     カンマで分けられたリスト，例えば`-Ddomain1.com,domain2.com'で，一
     つ以上のアドレスを指定することが可能です．

特定のドメインをダウンロードから除外したままにする--`--exclude-domains'
     指定から外したいドメインがある場合，`--exclude-domains'で行うこと
     が可能で，それは`-D'の引数と同じ形式を受け入れますが，リストアッ
     プされた全てのドメインを_除外_します．例えば，
     `sunsite.foo.edu'以外の`foo.edu'ドメインの，全てのホストをダ
     ウンロードしたい場合，以下のようにすることで可能です．

          wget -rH -Dfoo.edu --exclude-domains sunsite.foo.edu \
              http://www.foo.edu/


File: wget-ja.info,  Node: Types of Files,  Next: Directory-Based Limits,  Prev: Spanning Hosts,  Up: Following Links

ファイルの形式
==============

ウェブから資料をダウンロードするとき，特定のファイル形式のみを回収する
ように制限したいときもよくあります．例えば，GIFをダウンロードする
ことに興味がある場合，ポストスクリプトのドキュメントでの負荷は嬉しいは
ずが無く，逆もまたそうです．

Wgetはこの問題を扱う二つのオプションを提案します．それぞれのオプション
で，短い名前，長い名前，そして`.wgetrc'内の等価コマンドをリストアッ
プします．

`-A ACCLIST'
`--accept ACCLIST'
`accept = ACCLIST'
     `--accept'オプションの引数は，Wgetが再帰的な回収の間にダウンロー
     ドするファイルの，接尾子やパターンのリストです．接尾子はファイルの終り
     の部分で，"通常の"文字列，例えば`gif'や`.jpg'から成り立ち
     ます．パターンマッチはシェルのワイルドカードを含んでいて，例えば，
     `books*'や`zelazny*196[0-9]*'です．

     そして，`wget -A gif,jpg'を指定すると，Wgetは`gif'や
     `jpg'で終るファイルのみ，すなわちGIFとJPEGをダウンロー
     ドします．一方，`wget -A "zelazny*196[0-9]*"'は，`zelazny'で
     始まり，その中に1960から1969までの数字を含むファイルのみをダウンロード
     します．パターンマッチの動作方法についての記述はシェルのマニュアルを探
     してください．

     もちろん，任意の数の接尾子とパターンをカンマで分けたリストで組み合わせ
     ることや，`-A'の引数として与えることが可能です．

`-R REJLIST'
`--reject REJLIST'
`reject = REJLIST'
     `--reject'オプションは`--accept'と同じように動作しますが，そ
     の論理は否定です．Wgetは，リストの接尾子(やパターン)にマッチするもの
     _以外の_，全てのファイルをダウンロードします．

     そして，扱いにくいMPEGと.AUファイル以外の，ページ全体をダウ
     ンロードしたい場合，`wget -R mpg,mpeg,au'を使用できます．同様に，
     `bjork'で始まるファイル以外全てをダウンロードするため，`wget -R
     "bjork*"'を使用してください．引用符はシェルによる展開を妨げるためで
     す．

   `-A'と`-R'オプションは，回収するファイルでより良い調整を達成
するために組み合わせることができます．例えば，`wget -A "*zelazny*" -R
.ps'は，名前の一部に`zelazny'を持ち，ポストスクリ
プト_ではない_全てのファイルをダウンロードします．

   これら二つのオプションは，HTMLファイルのダウンロードで，効果が無
いことに注意してください．Wgetは全てのHTMLをリンク先を知るために
ロードする必要があります--再帰的な回収は，そうしなければ意味がありま
せん．


File: wget-ja.info,  Node: Directory-Based Limits,  Next: Relative Links,  Prev: Types of Files,  Up: Following Links

ディレクトリベースの制限
========================

他のリンクを追う能力にもかかわらず，ファイルがあるディレクトリをもとに
して回収するファイルの制限を行なうことが役に立つときも良くあります．こ
れには多くの理由があります--ホームページは合理的なディレクトリ構造に
組織化されている可能性があります．また，いくつかのディレクトリ，例えば
`/cgi-bin'や`/dev'といったディレクトリは，無用な情報を含んで
いる可能性があります．

Wgetは，これらの要求を扱うために三つの異なるオプションを提案します．そ
れぞれのオプションでは，短い名前，長い名前，そして`.wgetrc'内の等
価コマンドをリストアップしています．

`-I LIST'
`--include LIST'
`include_directories = LIST'
     `-I'オプションは，カンマで分けられた回収に含めるディレクトリのリ
     ストを受け入れます．他のあらゆるディレクトリは単に無視されます．ディレ
     クトリは絶対パスです．

     そのため，`http://host/people/bozo/'から`/people'ディレクト
     リのbozoの仲間へのリンクと`/cgi-bin'の偽りのスクリプトのみだどっ
     てダウンロードしたい場合，以下のように指定できます．

          wget -I /people,/cgi-bin http://host/people/bozo/

`-X LIST'
`--exclude LIST'
`exclude_directories = LIST'
     `-X'オプションは`-I'の正反対です--これは，ダウンロードから
     _除外する_ディレクトリのリストです．例えば，Wgetで`/cgi-bin'
     ディレクトリからのものをダウンロードしたくない場合，コマンドラインで
     `-X /cgi-bin'を指定してください．

     `-A'/`-R'と同様に，これら二つのオプションは，サブディレクト
     リのダウンロードでより良く調整するため，組み合わせることが可能です．例
     えば，`/pub/worthless'以外の`/pub'階層からの全てをロードした
     い場合，`-I/pub -X/pub/worthless'を指定してください．

`-np'
`--no-parent'
`no_parent = on'
     最も単純な，ディレクトリを制限するためによく利用される便利な方法は，開
     始より_上の_階層を参照するリンクの回収を許可しないことで，すなわ
     ち，親のディレクトリ等への上昇を許可しないことです．

     `--no-parent'オプション(短いものは`-np')はこの状況で役に立ち
     ます．それを利用することで，今いる階層から出ないことを保証します．Wget
     を以下のようにして呼び出したとします．

          wget -r --no-parent http://somehost/~luzer/my-archive/

     これは，`/~his-girls-homepage/'や`/~luzer/all-my-mpegs/'へ参
     照するものは参照するものをたどらないので安心できます．興味があるアーカ
     イブのみダウンロードされます．特に，それはより知的な方法でリダイレクト
     を処理するだけなので，`--no-parent'は`-I/~luzer/my-archive'
     に似ています．


File: wget-ja.info,  Node: Relative Links,  Next: FTP Links,  Prev: Directory-Based Limits,  Up: Following Links

相対的なリンク
==============

   `-L'が開始される時，相対リンクのみ回収されます．相対リンクは，こ
こではウェブサーバのルートを参照しないものと定義します．例えば以下のリ
ンクは相対的なものです．

     <a href="foo.gif">
     <a href="foo/bar.gif">
     <a href="../foo/bar.gif">

   以下のリンクは相対的ではありません．

     <a href="/foo.gif">
     <a href="/foo/bar.gif">
     <a href="http://www.server.com/foo/bar.gif">

   このオプションを使用することで，`-H'を用いない場合でも，再帰的な
回収でホストをまたがないことを保証します．単純な状況では，リンクを変換
すること無く"正しく動作する"ダウンロードも可能になります．

このオプションは，おそらくそんなには役に立たず，将来のリリースでは削除
されるかもしれません．


File: wget-ja.info,  Node: FTP Links,  Prev: Relative Links,  Up: Following Links

FTPリンクをだどる
=================

   FTPの規則は，必要があって若干特殊になっています．HTMLドキュ
メントのFTPリンクは参照の目的を含むことが多く，デフォルトでダウン
ロードすることが不便なことがよくあります．

   HTMLドキュメントからFTPへのリンクをたどらせるため，
`--follow-ftp'オプションを指定する必要があります．そうすることで，
FTPリンクは，`-H'の設定にかかわらずホストをまたぎます．
FTPリンクがHTTPサーバと同じホストを示すことは滅多にないので，
これは理にかなっています．同じ理由から，`-L'オプションはそのよう
なダウンロードで効果がありません．一方，ドメインの受け入れ(`-D')
と接尾子の規則(`-A'と`-R')は通常適用されます．

   また，FTPディレクトリへのリンクをたどることは，再帰的回収以上では
ないことに注意してください．


File: wget-ja.info,  Node: Time-Stamping,  Next: Startup File,  Prev: Following Links,  Up: Top

タイムスタンプ
**************

インターネットからの情報のミラーの側面で最も重要なことの一つは，アーカ
イブの更新です．

アーカイブを何度も何度もダウンロードすると，わずかに変更されたファイル
の置換だけでは勿体なく，それは，帯域幅とお金の無駄使いの両方を意味し，
更新する時間も無駄になります．これは，全てのミラーツールが逐次的な更新
のオプションを提案する理由です．

   そのような更新メカニズムは，リモートサーバが"新しい(new)"ファイル
の検索でスキャンされることを意味します．これらの新しいファイルのみ古い
ものに置換されます．

以下の二つの条件のどちらか一つが当てはまる場合，ファイルは新しいものと
考えられます．

  1. その名前のファイルが，ローカルにまだ存在しない．

  2.
     その名前のファイルが存在するが，リモートファイルがローカルファイルより
     後で編集されている．

これを実装するため，プログラムは，ローカルとリモートの両方のファイルが
最後に更新された時間に気付いている必要があります．そのような情報を，我々
はファイルの"タイムスタンプ(time-stamp)"と呼びます．

   The time-stamping in GNU Wget is turned on using `--timestamping'
(`-N') option, or through `timestamping = on' directive in `.wgetrc'.
With this option, for each file it intends to download, Wget will check
whether a local file of the same name exists.  If it does, and the
remote file is older, Wget will not download it.

   GNU Wgetのタイムスタンプは，`--timestamping' (`-N')オプショ
ンや，`.wgetrc'での`timestamping = on'の命令を通じて開始され
ます．このオプションでそれぞれのファイルをダウンロードするため，Wgetは
存在する同じ名前のローカルファイルを調査します．それが存在しリモートファ
イルが古い場合，Wgetはそれをダウンロードしません．

ローカルファイルが存在しない場合やファイルサイズが一致しない場合，Wget
はタイムスタンプを気にせずに，リモートファイルをダウンロードします．

* Menu:

* Time-Stamping Usage::
* HTTP Time-Stamping Internals::
* FTP Time-Stamping Internals::


File: wget-ja.info,  Node: Time-Stamping Usage,  Next: HTTP Time-Stamping Internals,  Prev: Time-Stamping,  Up: Time-Stamping

タイムスタンプの利用
====================

タイムスタンプの利用は単純です．編集日時を保つため，ダウンロードしたい
ファイルに対し以下のようにします．

     wget -S http://www.gnu.ai.mit.edu/

   単純に`ls -l'すると，ローカルファイルのタイムスタンプが，サーバか
ら返されるような`Last-Modified'のステータスと同じになります．タイ
ムスタンプ情報は，見て分かるように，たとえ`-N'がない場合でも(少く
ともHTTPに対し)ローカルに維持されます．

数日後，Wgetにリモートファイルが変化したかどうか調査させ，変化した場合
ダウンロードしたい場合もあります．

     wget -N http://www.gnu.ai.mit.edu/

Wgetはサーバに最後に編集した日付を尋ねます．ローカルファイルがサーバと
同じタイムスタンプ，またはより新しい場合，リモートファイルは再取得され
ません．しかし，リモートファイルがより最新の場合，Wgetは取得処理を行い
ます．

   The same goes for FTP.  For example:

   FTPでも同じようになります．例えば以下のようにします．

     wget "ftp://ftp.ifi.uio.no/pub/emacs/gnus/*"

   (URLの周りの引用符で，シェルが`*'を展開することを妨げます．)

ダウンロード後にローカルディレクトリをリスト表示すると，リモートサーバ
のものと一致するタイムスタンプを表示します．`-N'でコマンドを再発
行することで，Wgetは，前回ダウンロードしてから編集されたファイル
_のみ_再び回収します．

   毎週，GNUアーカイブをミラーしたい場合，毎週以下のコマンドを入力するで
しょう．

     wget --timestamping -r ftp://ftp.gnu.org/pub/gnu/

タイムスタンプは，サーバがタイムスタンプを与えるファイルに対してのみ動
作します．HTTPに対しては，これは`Last-Modified'ヘッダに依存
します．FTPに対しては，これはWgetがパース可能な書式の，日付を用い
たディレクトリリストで得られるものに依存します(*note FTP Time-Stamping
Internals::).


File: wget-ja.info,  Node: HTTP Time-Stamping Internals,  Next: FTP Time-Stamping Internals,  Prev: Time-Stamping Usage,  Up: Time-Stamping

HTTPタイムスタンプの内部
========================

   HTTPのタイムスタンプは，`Last-Modified'ヘッダの調査により実
行されます．HTTPでファイル`foo.html'を回収したい場合，Wgetは
`foo.html'がローカルに存在しているかどうかを調べます．存在しない
場合，`foo.html'は無条件に回収されます．

ローカルにファイルがある場合，Wgetは最初にローカルのタイムスタンプを調
べ(`ls -l'でそれを調べることに似ています)，そして，リモートファイ
ルの情報を要求するため，`HEAD'要求をリモートサーバに送ります．

   `Last-Modified'ヘッダは，ファイルがより最近編集され("新しく"され)
たことを知るために調査されます．リモートファイルがより新しい場合，ダウン
ロードされます．古い場合，Wgetは諦めます．(1)

   `-N'とともに`--backup-converted' (`-K')が指定されている
とき，サーバファイル`X'は，それが現存している場合はローカル
ファイルの`X.orig'と比較され，ローカルファイル
`X'と比較されません--`--convert-links' (`-k')で
変換されている場合は常に異なっています．

   おそらく，HTTPタイムスタンプは`If-Modified-Since'要求を使用
して実装されるべきです．

   ---------- Footnotes ----------

   (1) 追加の調査として，
Wgetは`Content-Length'ヘッダを見て，そして大きさを比較します．同じ
ではない場合，リモートファイルはタイムスタンプ告げることにかかわらず，ダ
ウンロードされます．


File: wget-ja.info,  Node: FTP Time-Stamping Internals,  Prev: HTTP Time-Stamping Internals,  Up: Time-Stamping

FTPタイムスタンプの内部
=======================

   理論上，FTPタイムスタンプはHTTPと同じように動作しますが，
FTPにはヘッダがありません--タイムスタンプはディレクトリリストか
ら探し出す必要があります．

   FTPダウンロードが，再帰的またはglobを使用している場合，ディレクト
リが含んでいる要求されたファイルに対してファイルリストを取得するために，
WgetはFTP `LIST'コマンドを使用します．それはリストの解析を試
み，それをUnixの`ls -l'の出力のように扱い，タイムスタンプを抽出し
ます．残りはHTTPに対するものと全く同じです．FTPサーバから
globや再帰を使用しないで個別のファイルを回収する時，`-N'を指定し
ない限りリストアップされたファイルはダウンロードされません(そして，こ
のためファイルにタイムスタンプは付きません)．

全てのディレクトリリストがUnix形式のリストだという仮定は，非常に不自然
に感じるかもしれませんが，経験的にはそうではなく，その理由は，ほとんど
(全て?)のクライアントがそれを理解できるので，多くの非Unix FTPサー
バでもUnixのようなリスト書式を使用しているためです．RFC959定義が，
タイムスタンプは言うまでもなく，ファイルリストを取得する標準的な方法で
はないことを覚えておいてください．我々は，将来の標準がこのように定義さ
れることを期待することしかできません．

   もう一つの非標準の解決方法は，(評判のよい`wu-ftpd'を含め)いくつか
のFTPサーバがサポートする`MDTM'コマンドの使用も含まれていて，
それは指定したファイルの正確な時間を返します．Wgetは，将来このコマンド
をサポートするかもしれません．


File: wget-ja.info,  Node: Startup File,  Next: Examples,  Prev: Time-Stamping,  Up: Top

スタートアップファイル
**********************

コマンドライン引数でWgetのデフォルト設定を変更する方法を知ると，これら
の設定を永久的に行いたいと思うかもしれません．Wgetスタートアップファイ
ル-- `.wgetrc'--を作成するという便利な方法でそうすることが可能 です．

   さらに，`.wgetrc'は"主な"初期化ファイルとなっていて，強固なパス
ワードに対する特別な能力があるので便利です．このためWgetは，
`$HOME/.netrc'がある場合は，その内容を読み込み解釈します．
`.netrc'書式はシステムのマニュアルで見つかります．

   Wgetは，限定されたコマンド群を認識し，スタートアップ時に`.wgetrc'
を読みます．

* Menu:

* Wgetrc Location::   Location of various wgetrc files.
* Wgetrc Syntax::     Syntax of wgetrc.
* Wgetrc Commands::   List of available commands.
* Sample Wgetrc::     A wgetrc example.


File: wget-ja.info,  Node: Wgetrc Location,  Next: Wgetrc Syntax,  Prev: Startup File,  Up: Startup File

Wgetrcの場所
============

   初期化時，Wgetはデフォルトで`/usr/local/etc/wgetrc'(または，Wget
がそこにインストールされていない場合，`/usr/local'ではない接頭辞)
にある"global"なスタートアップファイルを探し，存在する場合はそれか
らコマンドを読み込みます．

   それから，ユーザファイルを探します．環境変数`WGETRC'が設定されて
いる場合，そのファイルをロードしようとします．失敗した場合，それ以上何
もしません．

   `WGETRC'が設定されていない場合，Wgetは`$HOME/.wgetrc'をロー
ドしようとします．

ユーザ設定がシステム全体のものの後にロードされるということは，ユーザの
wgetrcと衝突した場合，システム全体のwgetrc(デフォルトで
`/usr/local/etc/wgetrc')に_優先_するということを意味します．
全体主義の管理者は不在です！


File: wget-ja.info,  Node: Wgetrc Syntax,  Next: Wgetrc Commands,  Prev: Wgetrc Location,  Up: Startup File

Wgetrcの構文
============

   wgetrcコマンドの構文は単純です．

     variable = value

   "変数(variable)"は"コマンド(command)"とも呼ばれます．有効な
"値(value)"はコマンドによって異なります．

   コマンドは大文字小文字とアンダースコアを識別しません．このため，
`DIr__PrefiX'は`dirprefix'と同じです．`#'で始まる行と空
白のみ含む行は，空行として捨てられます．

カンマで分けられたリストを期待するコマンドは，空のコマンドでリストをク
リアします．そのため，全体的な`wgetrc'で指定された拒絶するリスト
をリセットしたい場合，以下のようにして行うことができます．

     reject =


File: wget-ja.info,  Node: Wgetrc Commands,  Next: Sample Wgetrc,  Prev: Wgetrc Syntax,  Up: Startup File

Wgetrcコマンド
==============

コマンドの完全な組合わせは，以下にリストアップされています．正当な値は，
`='以下にリストアップされています．単純な真偽値は，`on'と
`off'，または`1'と`0'で，設定または解除ができます．場合
によっては利用可能な，変った種類の真偽値は"lockable Boolean"で，そ
れは，`on'，`off'，`always'，または`never'に設定可
能です．オプションが`always'や`never'に設定されている場合，
Wgetの呼び出しの間中，値は固定されます--コマンドラインオプションは優
先されません．

   コマンドには，擬似的に任意の値をとるものもあります．ADDRESS値は
ホスト名やドットで分けられたIPアドレスが可能です．Nはあらゆる正
の整数や，該当する場合は無限に対する`inf'が利用可能です．
STRING値は，空ではないあらゆる文字列が可能です．

   これらのほとんどのコマンドは，コマンドラインと同じですが (*note
Invoking::)，時代遅れのものや滅多に使用されないものもあります．

accept/reject = STRING
     `-A'/`-R' (*note Types of Files::)と同じです．

add_hostdir = on/off
     ホストが前置されたファイル名を利用可/不可にします．`-nH'はそれを
     不可にします．

continue = on/off
     オンに設定した場合，前から存在している部分的に回収されたファイルに強制
     的につなげます．それを設定する前に`-c'を参照して下さい．

background = on/off
     バックグランドへの移行を可/不可にします--`-b'(利用可にする)と同
     じです．

backup_converted = on/off
     前もって接尾子`.orig'に変換されているファイルの保存を利用可能/不
     可能にします--(可能にする)`-K'と同じです．

base = STRING
     URL入力ファイル内の相対的なURLが，STRINGに相対的な
     HTMLとして解釈させることを強制されていると考えます--`-B'と
     同じです．

bind_address = ADDRESS
     ADDRESSをbindし，それは`--bind-address'オプションに似ていま す．

cache = on/off
     オフに設定するとき，サーバキャッシュを不可にします．`-C'オプショ
     ンを参照してください．

convert links = on/off
     相対的でないリンクをローカルに変換します．それは`-k'と同じです．

cookies = on/off
     オフに設定するときクッキーは利用できません．`--cookies'オプション
     を参照してください．

load_cookies = FILE
     FILEからクッキーをロードします．`--load-cookies'オプション
     を参照してください．

save_cookies = FILE
     FILEにクッキーを保存します．`--save-cookies'オプションを参
     照してください．

connect_timeout = N
     接続のタイムアウトを設定します--`--connect-timeout'と同じです．

cut_dirs = N
     N個のリモートディレクトリコンポーネントを無視します．

debug = on/off
     デバッグモードで，それは`-d'と同じです．

delete_after = on/off
     ダウンロード後削除します--`--delete-after'と同じです．

dir_prefix = STRING
     ディレクトリツリーのトップです--`-P'と同じです．

dirstruct = on/off
     ディレクトリ構造のオン/オフを切替えます--それぞれ`-x'や
     `-nd'と同じです．

dns_cache = on/off
     DNSのキャッシュのオン/オフを切替えます．DNSのキャッシュはデフォルトで
     オンで，このオプションは通常オフにするために使用します．
     `--dns-cache'と同じです．

dns_timeout = N
     DNSのタイムアウトを設定します．`--dns-timeout'と同じです．

domains = STRING
     `-D' (*note Spanning Hosts::)と同じです．

dot_bytes = N
     回収中に見ている1ドットが"含む"バイト数(デフォルトで1024)を指定しま
     す．値に`k'や`m'を後置することが可能で，それぞれキロバイトと
     メガバイトの代替となります．ドットの設定では，必要に応じてドットの回収
     を適応させたり，前もって定義された"styles"を使用することも可能です
     (*note Download Options::)．

dots_in_line = N
     回収中にそれぞれの行に出力するドットの数(デフォルトで50)を指定します．

dot_spacing = N
     1クラスタのドットの数(デフォルトで10)を指定します．

exclude_directories = STRING
     ダウンロードから除外したいディレクトリのカンマで分けられたリストを指定
     します--`-X' (*note Directory-Based Limits::)と同じです．

exclude_domains = STRING
     `--exclude-domains' (*note Spanning Hosts::)と同じです．

follow_ftp = on/off
     HTMLドキュメントからFTPリンクをたどります--
     `--follow-ftp'と同じです．

follow_tags = STRING
     再帰的な回収時に特定のHTMLタグのみたどり，それは
     `--follow-tags'に似ています．

force_html = on/off
     オンに設定された場合，入力ファイル名がHTMLドキュメントと同じと見
     なすことを強制します--`-F'と同じです．

ftp_proxy = STRING
     環境変数で指定されたものの代わりに，STRINGをFTPプロキシとし
     て使用します．

glob = on/off
     globをオン/オフします--`-g'と同じです．

header = STRING
     `--header'のように，追加ヘッダを定義します．

html_extension = on/off
     `.html'拡張子を，それが無い`text/html'ファイルや
     `application/xhtml+xml'ファイルに追加し，それは`-E'に似てい ます．

http_passwd = STRING
     HTTPパスワードを設定します．

http_proxy = STRING
     環境変数で指定されたものの代わりに，STRINGをHTTPプロキシと
     して使用します．

http_user = STRING
     HTTPユーザをSTRINGに設定します．

ignore_length = on/off
     オンに設定した場合，`Content-Length'ヘッダを無視します．
     `--ignore-length'と同じです．

ignore_tags = STRING
     再帰的な回収時に特定のHTMLタグを無視し，それは`-G' /
     `--ignore-tags'に似ています．

include_directories = STRING
     ダウンロード時にだどりたい，カンマで分けられたディレクトリのリストを指
     定します--`-I'と同じです．

input = STRING
     `-i'のように，STRINGからURLを読み込みます．

kill_longer = on/off
     content-lengthヘッダで指定されているより長いデータを無効だと考えます
     (そして所得を試みます)．デフォルトの動作はそこにあるデータと同じだけ保
     存し，つまり`Content-Length'の値より大きいまたは同じであると規定
     されます．

limit_rate = RATE
     ダウンロードの速度をRATEバイト毎秒以下に設定します．
     `--limit-rate'と同じです．

logfile = STRING
     ログファイルを設定します--`-o'と同じです．

login = STRING
     FTPに対するリモートマシンでのユーザ名です．デフォルトは
     `anonymous'です．

mirror = on/off
     ミラーリングをオン/オフします．`-m'と同じです．

netrc = on/off
     netrcの読み込みをオン/オフします．

noclobber = on/off
     `-nc'と同じです．

no_parent = on/off
     ディレクトリ階層外部への回収を禁止し，それは`--no-parent' (*note
     Directory-Based Limits::)に似ています．

no_proxy = STRING
     環境変数で指定したものの代わりに，プロキシの負荷を避けるため，
     STRINGを，カンマで分けられたドメインのリストとして使用します．

output_document = STRING
     出力ファイル名を設定します--`-O'と同じです．

page_requisites = on/off
     単一のHTMLページを正しく表示するのに必要な補助的なドキュメントを
     すべてダウンロードします--`-p'と同じです．

passive_ftp = on/off/always/never
     パッシブFTPに設定します--`--passive-ftp'と同じです．いくつ
     かのスクリプトと`.pm' (Perlモジュール)ファイルは，`wget
     --passive-ftp'を使用しているファイルをダウンロードします．ファイアウォー
     ルがこれを許可しない場合，コマンドラインを優先するため
     `passive_ftp = never'を指定できます．

passwd = STRING
     FTPパスワードをPASSWORDに設定します．設定していない場合パス
     ワードのデフォルトは`username@hostname.domainname'です．

post_data = STRING
     すべてのHTTPリクエストに対する手法としてPOSTを使用し，リクエストの本体
     にSTRINGを送ります．`--post-data'と同じです．

post_file = FILE
     すべてのHTTPリクエストに対する手法としてPOSTを使用し，リクエストの本体
     にFILEの内容を送ります．`--post-file'と同じです．

progress = STRING
     進行状況の表紙の形式を設定します．正当な形式は，"dot(ドット)"と
     "bar(バー)"です．

proxy_user = STRING
     `--proxy-user'のように，プロキシ認証のユーザ名をSTRINGに設
     定します．

proxy_passwd = STRING
     `--proxy-passwd'のように，プロキシ認証のパスワードをSTRING
     に設定します．

referer = STRING
     HTTP `Referer:'ヘッダを`--referer'のように設定します．(それ
     は，間違った"referrer"の綴りを知っていた人が，HTTPスペックを書
     いた人々だということに注意してください．)

quiet = on/off
     静かなモードです--`-q'と同じです．

quota = QUOTA
     ダウンロードのクォータを指定し，それは全体的な`wgetrc'に置くと便
     利です．ダウンロードクォータが指定された場合，Wgetは，ダウンロードの合
     計がクォータより大きくなった後で回収を停止します．クォータはバイト(デ
     フォルト)，キロバイト(`k'の追加)，またはメガバイト(`m'の追加)
     で指定できます．このため，`quota = 5m'はクォータを5メガバイトに設
     定します．ユーザのスタートアップファイルがシステム設定に優先することに
     注意してください．

read_timeout = N
     読み込み(と書き込み)のライムアウトを設定します．`--read-timeout'
     と同じです．

reclevel = N
     再帰の階層です--`-l'と同じです．

recursive = on/off
     再帰をオン/オフします--それは`-r'と同じです．

relative_only = on/off
     相対リンクのみをたどります--`-L' (*note Relative Links::)と同じ
     です．

remove_listing = on/off
     オンに設定したとき，WgetがダウンロードしたFTPのリストを削除します．
     オフに設定することは，`-nr'と同じです．

restrict_file_names = unix/windows
     URLからWgetが生成するファイル名を制限します．詳細な記述は
     `--restrict-file-names'を参照してください．

retr_symlinks = on/off
     オンに設定したとき，シンボリックリンクをプレーンファイルであるかのよう
     に回収します．`--retr-symlinks'と同じです．

robots = on/off
     Wgetが遵守するロボット拒否の慣習を指定し，"on(オン)"がデフォルトです．
     この切替えは，`/robots.txt'と`nofollow'で指定されたものを制
     御します．これに関する詳細は*Note Robot Exclusion::.
     これを停止する前
     に，自分が行っていることが分かっているか確かめてください．

server_response = on/off
     HTTPとFTPサーバのレスポンスの出力を行うかどうか選択します--
     `-S'と同じです．

span_hosts = on/off
     `-H'と同じです．

strict_comments = on/off
     `--strict-comments'と同じです．

timeout = N
     タイムアウトの値を設定します--`-T'と同じです．

timestamping = on/off
     タイムスタンプのオン/オフを切替えます．`-N' (*note
     Time-Stamping::) と同じです．

tries = N
     URLごとの再挑戦回数を設定します--`-t'と同じです．

use_proxy = on/off
     プロキシサポートのオン/オフを切替えます．`-Y'と同じです．

verbose = on/off
     冗長出力のオン/オフを切替えます--`-v'/`-nv'と同じです．

wait = N
     回収の間でN秒待ちます--`-w'と同じです．

waitretry = N
     回収の失敗での再試行のみで，N秒まで待ちます-- `--waitretry'
     と同じです．これはデフォルトで，大域的な
     `wgetrc'で開始されることに注意してください．

randomwait = on/off
     要求間のランダムな待ち時間をオンまたはオフにします．
     `--random-wait' と同じです．


File: wget-ja.info,  Node: Sample Wgetrc,  Prev: Wgetrc Commands,  Up: Startup File

Wgetrcの見本
============

以下は，配布物で与えられる初期化ファイルの例です．それは二つの部分に分
けられます--一つは全体的な使用で(全体的なスタートアップファイルに適し
ています)，もう一つはローカルで使用するもの(`$HOME/.wgetrc'に適し
ています)です．変更には注意してください．

ほとんど全ての行がコメントアウトされていることに注意してください．効果
を得たいあらゆる行に対し，行の前に前置された`#'を削除する必要があ
ります．

     ###
     ### Sample Wget initialization file .wgetrc
     ###
     
     ## You can use this file to change the default behaviour of wget or to
     ## avoid having to type many many command-line options. This file does
     ## not contain a comprehensive list of commands -- look at the manual
     ## to find out what you can put into this file.
     ##
     ## Wget initialization file can reside in /usr/local/etc/wgetrc
     ## (global, for all users) or $HOME/.wgetrc (for a single user).
     ##
     ## To use the settings in this file, you will have to uncomment them,
     ## as well as change them, in most cases, as the values on the
     ## commented-out lines are the default values (e.g. "off").
     
     
     ##
     ## Global settings (useful for setting up in /usr/local/etc/wgetrc).
     ## Think well before you change them, since they may reduce wget's
     ## functionality, and make it behave contrary to the documentation:
     ##
     
     # You can set retrieve quota for beginners by specifying a value
     # optionally followed by 'K' (kilobytes) or 'M' (megabytes).  The
     # default quota is unlimited.
     #quota = inf
     
     # You can lower (or raise) the default number of retries when
     # downloading a file (default is 20).
     #tries = 20
     
     # Lowering the maximum depth of the recursive retrieval is handy to
     # prevent newbies from going too "deep" when they unwittingly start
     # the recursive retrieval.  The default is 5.
     #reclevel = 5
     
     # Many sites are behind firewalls that do not allow initiation of
     # connections from the outside.  On these sites you have to use the
     # `passive' feature of FTP.  If you are behind such a firewall, you
     # can turn this on to make Wget use passive FTP by default.
     #passive_ftp = off
     
     # The "wait" command below makes Wget wait between every connection.
     # If, instead, you want Wget to wait only between retries of failed
     # downloads, set waitretry to maximum number of seconds to wait (Wget
     # will use "linear backoff", waiting 1 second after the first failure
     # on a file, 2 seconds after the second failure, etc. up to this max).
     waitretry = 10
     
     
     ##
     ## Local settings (for a user to set in his $HOME/.wgetrc).  It is
     ## *highly* undesirable to put these settings in the global file, since
     ## they are potentially dangerous to "normal" users.
     ##
     ## Even when setting up your own ~/.wgetrc, you should know what you
     ## are doing before doing so.
     ##
     
     # Set this to on to use timestamping by default:
     #timestamping = off
     
     # It is a good idea to make Wget send your email address in a `From:'
     # header with your request (so that server administrators can contact
     # you in case of errors).  Wget does *not* send `From:' by default.
     #header = From: Your Name <username@site.domain>
     
     # You can set up other headers, like Accept-Language.  Accept-Language
     # is *not* sent by default.
     #header = Accept-Language: en
     
     # You can set the default proxies for Wget to use for http and ftp.
     # They will override the value in the environment.
     #http_proxy = http://proxy.yoyodyne.com:18023/
     #ftp_proxy = http://proxy.yoyodyne.com:18023/
     
     # If you do not want to use proxy at all, set this to off.
     #use_proxy = on
     
     # You can customize the retrieval outlook.  Valid options are default,
     # binary, mega and micro.
     #dot_style = default
     
     # Setting this to off makes Wget not download /robots.txt.  Be sure to
     # know *exactly* what /robots.txt is and how it is used before changing
     # the default!
     #robots = on
     
     # It can be useful to make Wget wait between connections.  Set this to
     # the number of seconds you want Wget to wait.
     #wait = 0
     
     # You can force creating directory structure, even if a single is being
     # retrieved, by setting this to on.
     #dirstruct = off
     
     # You can turn on recursive retrieving by default (don't do this if
     # you are not sure you know what it means) by setting this to on.
     #recursive = off
     
     # To always back up file X as X.orig before converting its links (due
     # to -k / --convert-links / convert_links = on having been specified),
     # set this variable to on:
     #backup_converted = off
     
     # To have Wget follow FTP links from HTML files by default, set this
     # to on:
     #follow_ftp = off


File: wget-ja.info,  Node: Examples,  Next: Various,  Prev: Startup File,  Up: Top

例
**

   例は，その複雑さから大まかに三つのセクションに分けています．

* Menu:

* Simple Usage::         Simple, basic usage of the program.
* Advanced Usage::       Advanced tips.
* Very Advanced Usage::  The hairy stuff.


File: wget-ja.info,  Node: Simple Usage,  Next: Advanced Usage,  Prev: Examples,  Up: Examples

簡単な使用方法
==============

   * URLをダウンロードしたいとします．以下のように入力します．

          wget http://fly.srk.fer.hr/

   *
     しかし，接続が遅い場合やファイルが長いとき，何が生じるのでしょうか？接
     続は，ファイル全体を回収する前に一度以上失敗するでしょう．この場合，
     Wgetはファイル全体を取得する，または再挑戦の回数(デフォルトで20)を越え
     るまで，ファイルの取得を試みます．ファイル全体を安全に得ることを保証す
     るため，試みる回数を45に変更することは簡単です．

          wget --tries=45 http://fly.srk.fer.hr/jpg/flyweb.jpg

   *
     さて，Wgetがバックグラウンドで動作するようにし，その進捗状況をログファ
     イル`log'に書き出します．`--tries'と入力する面倒なので，我々
     は`-t'を使用します．

          wget -t 45 -o log http://fly.srk.fer.hr/jpg/flyweb.jpg &

     行の終りのアンパサンドはWgetがバックグラウンドで動作することを確実にし
     ます．再挑戦の回数を無制限にするため，`-t inf'を使用してください．

   * FTPの使用は単純です．Wgetはログインとパスワードの面倒もみます．

          wget ftp://gnjilux.srk.fer.hr/welcome.msg

   *
     ディレクトリを指定する場合，Wgetはディレクトリリストを回収し，それを解
     析し，HTMLに変換します．以下を試してみてください．

          wget ftp://ftp.gnu.org/pub/gnu/
          links index.html


File: wget-ja.info,  Node: Advanced Usage,  Next: Very Advanced Usage,  Prev: Simple Usage,  Up: Examples

高度な使用方法
==============

   * ダウンロードを行ないたいURLを含むファイルがあるでしょうか？`-i'を
     使用します．

          wget -i FILE

     ファイル名として`-'を指定した場合，URLは標準入力から読み込ま
     れます．

   * GNUのウェブサイトの五階層までの深さのミラーイメージを，動作のログを
     `gnulog'に保存しながら，オリジナルと同じディレクトリ構造で，ドキュ
     メントごとに一度の挑戦だけで作成します．

          wget -r http://www.gnu.org/ -o gnulog

   *
     以下は上記と同じですが，オフラインでドキュメントが閲覧できるように，
     HTMLファイル内のリンクをローカルファイルを指し示すものに変換しま
     す．

          wget --convert-links -r http://www.gnu.org/ -o gnulog

   * 一つのHTMLのみを回収し，内部の画像と外部のスタイルシートもダウン
     ロードされるように，そのページを表示するために必要な全ての要素が確実に
     回収します．また，ダウンロードされたリンクもダウンロードしたページを確
     実に参照します．

          wget -p --convert-links http://www.server.com/dir/page.html

     HTMLページは`www.server.com/dir/page.html'に保存され，そして
     画像とスタイルシートなども，リモートのサーバにあった場所に依存して，
     `www.server.com/'以下に保存されます．

   * 上記と同じですが，`www.server.com/'ディレクトリを用いないようにし
     ます．実際，これらのランダムなサーバディレクトリを全く持ちたいとは思い
     ません--現在のディレクトリのサブディレクトリ`download/'以下に，
     これらのファイル_全部_をそのまま保存したいと思います．

          wget -p --convert-links -nH -nd -Pdownload \
               http://www.server.com/dir/page.html

   * オリジナルのサーバのヘッダを表示しながら，`www.lycos.com'の
     index.htmlを回収します．

          wget -S http://www.lycos.com/

   * サーバヘッダをファイルに保存し，それはおそらく処理後のためです．

          wget -s http://www.lycos.com/
          more index.html

   * `wuarchive.wustl.edu'の最初の二階層を回収し，`/tmp'に保存し ます．

          wget -r -l2 -P/tmp ftp://wuarchive.wustl.edu/

   * HTTPサーバ上のディレクトリから全てのGIFダウンロードしたいと
     します．`wget http://host/dir/*.gif'を試しても，HTTPの回収は
     globをサポートしないので動作しません．その場合は以下を使用してください．

          wget -r -l1 --no-parent -A.gif http://www.server.com/dir/

     より冗長ですが，効果は同じです．`-r -l1'は，最大深度が1の再帰的な
     回収(*note Recursive Retrieval::)を意味します．`--no-parent'は親
     ディレクトリへの参照を無視すること(*note Directory-Based
     Limits::)を意
     味し，`-A.gif'はGIFファイルのみをダウンロードすることを意味
     します．`-A "*.gif"'も動作します．

   *
     Wgetが中断されたときダウンロード中だったとします．さて，既に存在するファ
     イルを壊したくはありません．そして，以下のようにします．

          wget -nc -r http://www.gnu.org/

   * HTTPやFTPのユーザ名とパスワードを符号化したい場合，適切な
     URL構文(*note URL Format::)を使用してください．

          wget ftp://hniksic:mypassword@unix.server.com/.emacs

     しかし，この使用方法は，`ps'の出力を見たユーザにパスワードがされ
     られるので，複数ユーザのシステムでは推奨されないことに注意して下さい．

   *
     出力されるドキュメントをファイルの代わりに標準出力にしたいでしょうか？

          wget -O - http://jagor.srce.hr/ http://www.srce.hr/

     二つのオプションを組み合わせ，リモートのホットリストからドキュメントを
     回収するパイプラインを作成することも可能です．

          wget -O - http://cool.list.com/ | wget --force-html -i -


File: wget-ja.info,  Node: Very Advanced Usage,  Prev: Advanced Usage,  Up: Examples

非常に高度な使用方法
====================

   * ページ(またはFTPサブディレクトリ)のミラーをWgetに保持させたい場合，
     `-r -l inf -N'に対する省略形の`--mirror' (`-m')を使用し
     てください．日曜日ごとにサイトの再調査を依頼するため，Wgetをcrontabファ
     イルに書くことが可能です．

          crontab
          0 0 * * 0 wget --mirror http://www.gnu.org/ -o /home/me/weeklog

   *
     上記と同様に，ローカルで閲覧するためにリンクを変換したいとします．しか
     し，このマニュアルを読んだ後では，リンクの変換がタイムスタンプのように
     うまく動作しないことが分かるので，変換前にWgetにオリジナルのHTML
     ファイルをバックアップさせたいとします．Wgetの呼び出しは以下のようにな
     ります．

          wget --mirror --convert-links --backup-converted  \
               http://www.gnu.org/ -o /home/me/weeklog

   * しかし，HTMLファイルが`.html'以外の拡張子で保存されるときは，
     ローカルでの閲覧はうまく動作しないことに気付いていて，それはおそらく
     `index.cgi'として保存されているためです．そのためWgetで，
     content-type `text/html'の全てのファイルを， `NAME.html'
     に名前を変えたいことでしょう．

          wget --mirror --convert-links --backup-converted \
               --html-extension -o /home/me/weeklog        \
               http://www.gnu.org/

     または，より入力が少ない以下を用います．

          wget -m -k -K -E http://www.gnu.org/ -o /home/me/weeklog


File: wget-ja.info,  Node: Various,  Next: Appendices,  Prev: Examples,  Up: Top

様々なもの
**********

   この章には，どこにも適さなかったあらゆるものを含んでいます．

* Menu:

* Proxies::             Support for proxy servers
* Distribution::        Getting the latest version.
* Mailing List::        Wget mailing list for announcements and discussion.
* Reporting Bugs::      How and where to report bugs.
* Portability::         The systems Wget works on.
* Signals::             Signal-handling performed by Wget.


File: wget-ja.info,  Node: Proxies,  Next: Distribution,  Prev: Various,  Up: Various

プロキシ
========

   "プロキシ(Proxies)"は，リモートサーバからローカルクライアントにデー
タを転送するために設計された，特別な目的のHTTPサーバです．プロキ
シの一つの典型的な使用目的は，接続が遅い場所にいるユーザのためネットワー
ク負荷を軽くすることです．これは，転送したデータをキャッシュするプロキ
シを通じて，全てのHTTPとFTPの要求の経路を作ることで達成しま
す．キャッシュリソースが再び要求されたときプロキシはキャッシュからデー
タを返します．プロキシのもう一つの使用目的は，(セキュリティの理由で)イ
ンターネットと内部のネットワークを分けたいと考えている会社のためです．
Webから情報を得るため，それらのユーザは認証されたプロキシを使用してリ
モートデータに接続し回収します．

   Wgetは，HTTPとFTPの回収の両方でプロキシをサポートします． Wget
が認識できるようにプロキシの位置を指定する標準的な方法は，以下の
環境変数を使用する方法です．

`http_proxy'
     この変数には，HTTPに接続するためのプロキシのURLを含めるべき です．

`ftp_proxy'
     この変数には，FTPに接続するためのプロキシのURLを含めるべきで
     す．HTTP_PROXYとFTP_PROXYを同じURLに設定することは，一
     般的なことです．

`no_proxy'
     この変数は，カンマで分けられた，プロキシを使用_しない_ドメイン拡
     張子のリストです．例えば，`no_proxy'の値が`.mit.edu'の場合，
     プロキシはMITからのドキュメントの回収で使用されません．

   環境変数に加え，プロキシの位置や設定はWget自身から指定できます．

`-Y on/off'
`--proxy=on/off'
`proxy = on/off'
     このオプションは，プロキシサポートのオン/オフを切替えます．適切な環境
     変数が設定されている場合，プロキシサポートはデフォルトでオンです．

`http_proxy = URL'
`ftp_proxy = URL'
`no_proxy = STRING'
     これらのスタートアップファイル変数で，環境変数で指定されているプロキシ
     の設定に優先します．

プロキシサーバの使用を可能にするため，認証を要求するサーバもあります．
認証は，"ユーザ名(username)"と"パスワード(password)"から成り立
ち，それはWgetが送る必要があります．HTTP認証と同様，いくつかの認
証手法が存在します．プロキシ認証のために，`Basic'認証手法のみ，現
在実装されています．

   ユーザ名とパスワードを，プロキシのURLまたはコマンドラインオプショ
ンのどちらかで指定できます．会社のプロキシが`proxy.company.com'の
8001ポートにあると仮定すると，認証データを含むプロキシURLの位置は
以下のようになります．

     http://hniksic:mypassword@proxy.company.com:8001/

   代わりに，プロキシユーザ名とパスワードを設定するため，
`proxy-user'と`proxy-password'オプションと，その等価の
`.wgetrc'での`proxy_user'と`proxy_passwd'の設定を使用で きます．


File: wget-ja.info,  Node: Distribution,  Next: Mailing List,  Prev: Proxies,  Up: Various

配布
====

全てのGNUユーティリティのように，Wgetの最近のバージョンは，GNUアーカイ
ブサイトftp.gnu.orgとそのミラーで見つかります．例えば，Wget 1.9は，
<ftp://ftp.gnu.org/pub/gnu/wget/wget-1.9.tar.gz>で見付 かるはずです．


File: wget-ja.info,  Node: Mailing List,  Next: Reporting Bugs,  Prev: Distribution,  Up: Various

メーリングリスト
================

   Wgetは，Karsten Thygesenのおかげで，<wget@sunsite.dk>に独自のメー
リングリストがあります．メーリングリストは，Wgetの機能とwebの議論，
Wget のバグレポート(大衆にとって重要だと思うもの)，そしてメールでのア
ナウンスのためです．購読を歓迎します．リスト上の人々が多ければ多いほど
良いでしょう！

   購読するためには，単純に<wget-subscribe@sunsite.dk>にメールを送っ
てください．購読停止は<wget-unsubscribe@sunsite.dk>にメールを送
ることです．

   メーリングリストは<http://fly.srk.fer.hr/archive/wget>に保存されま
す．別のアーカイブとして
<http://www.mail-archive.com/wget%40sunsite.auc.dk/>で利用可能です．


File: wget-ja.info,  Node: Reporting Bugs,  Next: Portability,  Prev: Mailing List,  Up: Various

バグの報告
==========

   GNU Wgetに関するバグレポートを<bug-wget@gnu.org>に送ることを歓
迎します．

実際にバグレポートを提出する前に，以下のいくつかの単純なガイドラインに
従ってみてください．

  1.
     動作が本当にバグだということを確認してみてください．Wgetがクラッシュし
     た場合，それはバグです．Wgetがドキュメントのように動作しない場合，それ
     はバグです．奇妙な動作をするが，期待した動作をさせる方法が不明な場合，
     おそらくバグです．

  2.
     できるだけ単純な状況で，バグを繰り返してみてください．例えば，Wgetが
     `wget -rl0 -kKE -t5 -Y0 http://yoyodyne.com -o /tmp/log'をタウン
     ロードしている間にクラッシュする場合，クラッシュが再現されるかどうか，
     より単純なオプションの組み合わせでも発生するかどうか試してみるべきです．
     ページがクラッシュの引金になっているかどうかを調べるため，クラッシュが
     発生した場所のページでダウンロードを開始してみてください．

     また，`.wgetrc'の内容を知ることに興味がありはしますが，バグメッセー
     ジにそれをそのままダンプするのは，余り良い考えではありません．代わりに，
     `.wgetrc'を伴うバグの報告が間違っていないか，最初に確認してみるべ
     きです．`.wgetrc'の設定がバグに影響があることが分かる場合のみ，ファ
     イルの適切な部分をメールを送ってください．

  3. Wgetを`-d'オプションで開始し，ログ(または，その適切な部分)を送っ
     てください．Wgetがデバッグのサポート無しでコンパイルされている場合，再
     コンパイルしてください．デバッグサポートをオンにしたバグの追跡は
     _非常に_簡単になります．

  4.
     Wgetがクラッシュした場合，デバッガで動作してみてください．例えば，逆追
     跡するため，`gdb `which wget` core'とし`where'と入力します．


File: wget-ja.info,  Node: Portability,  Next: Signals,  Prev: Reporting Bugs,  Up: Various

移植
====

   Wgetは，構築とコンフィグレーションにGNU
Autoconfを使用していて，特定の
Unixの"特別な"超凄くカッコいい特徴の使用を避けているので，全ての一般
のUnixの類でコンパイル(と動作)可能でしょう．

様々なWgetのバージョンが，多種のUnixシステムでコンパイルされテストされ
ていて，それには，Solaris，Linux，SunOS，OSF (aka Digital Unix)，
Ultrix，*BSD，IRIX，その他を含みます．包括的なリストは，配布されたディ
レクトリのファイル`MACHINES'を参照してください．そこにリストアッ
プされていないアーキテクチャでコンパイルした場合，更新するために知らせ
てください．

   Wgetは，`MACHINES'にリストアップされていない，他のUnixシステムで
もコンパイルすべきです．そうでない場合は知らせてください．

   親切な貢献者のおかげで，Wgetのこのバージョンは，Microsoft Windows
95と Windows
NTのプラットホームで，コンパイルし動作します．それは，ネットワー
クソフトウェアとしてWinsockを用いて，MS Visual C++ 4.0，Watcom，そして
Borland Cコンパイラを使用してのコンパイルが成功しています．当然，Unix
で利用可能ないくつかの特徴に障害がありますが，Windowsを押しつけられて
いる人々に代用として動作します．Windowsの移植は，*テストも管理
もしていない*ことに注意してください--全ての疑問と問題は，管理者が注目
するように，<wget@sunsite.dk>のWgetメーリングリストに報告すべき です．


File: wget-ja.info,  Node: Signals,  Prev: Portability,  Up: Various

シグナル
========

Wgetの目的がバックグラウンドで動作することなので，ハングアップシグナル
(`SIGHUP')を受け取り，それを無視します．出力が標準出力の場合，ファ
イル名`wget-log'にリダイレクトされます．それ以外では， `SIGHUP'
は無視されます．これは，開始後Wgetの出力をリダイレクトし
たい場合便利です．

     $ wget http://www.ifi.uio.no/~larsi/gnus.tar.gz &
     $ kill -HUP %%     # Redirect the output to wget-log

   それ以外に，Wgetはあらゆるシグナルに干渉しようとしません．`C-c'，
`kill -TERM'と`kill -KILL'は同様にそれをキルします．


File: wget-ja.info,  Node: Appendices,  Next: Copying,  Prev: Various,  Up: Top

付録
****

   この章は，私が役に立つと考えるものへの参照も含んでいます．

* Menu:

* Robot Exclusion::         Wget's support for RES.
* Security Considerations:: Security with Wget.
* Contributors::            People who helped.


File: wget-ja.info,  Node: Robot Exclusion,  Next: Security Considerations,  Prev: Appendices,  Up: Appendices

ロボットの排除
==============

Wgetに，進行中に利用可能なすべてのデータを吸い上げながら，ウェブサイト
中をあてもなく歩きまわらせることは非常に簡単です．`wget -r
SITE'とその設定です．すばらしいでしょうか？サーバ管理者にとって
はそうではありません．

Wgetが静的なページを回収している限り，そして適切なレートで行なわれてい
る限り(`--wait'オプションを参照してください)，余り問題ありません．
問題は，Wgetが静的なページとほとんどのCGIを要求するページの間の違いを
伝えることができないことにあります．InfoファイルをHTMLに変換する CGI
Perlスクリプトで処理させるセクションを持つサイトを知っています．ス
クリプトは遅いのですが，人間のユーザが予備のInfoファイルを閲覧するのに
十分うまく動作します．しかし，Wgetで再帰ダウンロードしている人の中に，
スクリプト全体のすべてのInfoファイルへのリンクがある索引ページでつまづ
く人がいるとき，そのシステムはユーザが役に立つものを提供すること無くやっ
てきます(Infoファイルを変換するこの処理はローカルに行なわれるべきで，
インストールされているすべてのGNUのソフトウェアに対するInfoドキュメン
トは`info'コマンドで利用可能にすべきです)．

このような問題を避けるため，うまく動作するロボットから保護する必要があ
るドキュメントのプライバシーを保護することと同様に，"ロボット拒否
(robot exclusion)"の概念が導入されました．その考え方とは，サーバの管理
者とドキュメントの著者が，ロボットから保護したい，そしてアクセスを許可
したいサイトの部分を指定することを可能にすることです．

   最も人気のあるメカニズムで，すべての主要なロボットがサポートするデ
ファクトスタンダードは，"Robots Exclusion Standard" (RES)でMartijn
Koster他によって1994年に書かれました．それは，ロボットに避けて欲しい
URLパスを指示する命令を含むテキストファイルの書式を指定しています．ロ
ボットが見つけるように，ロボットがダウンロードし解析するということを期
待して，その指定はサーバのルートの`/robots.txt'に配置する必要があ
ります．

Wgetは，厳密な意味ではウェブロボットではありませんが，個別のページをダ
ウンロードするためにユーザが介入すること無く，サイトの大半をダウンロー
ドすることが可能です．そのため，再帰的なダウンロード時にはWgetはRESに
従います．例えば，以下のようにします．

     wget -r http://www.server.com/

   `www.server.com'の最初のインデクッスがダウンロードされます．Wget
がそのサーバからダウンロードするより多くのドキュメントを見つけた場合，
`http://www.server.com/robots.txt'を要求し，見つかった場合はそれ
以降のダウンロードでそれを使用します．`robots.txt'はそれぞれのサー
バごとに一回のみロードされます．

   バージョン1.8までのWgetは，Martijn Kosterが1994年に書いた
<http://www.robotstxt.org/wc/norobots.html>で利用可能な最初のバー
ジョンの標準をサポートしていました．バージョン1.8では，Wgetはインター
ネットドラフト`<draft-koster-robots-00.txt>'の"A Method for Web Robots
Control"と言うタイトルで指定された追加命令もサポートしています．
私の知る限りRFCにはなっていませんが，そのドラフトは
<http://www.robotstxt.org/wc/norobots-rfc.txt>で利用可能です．

   このマニュアルは，もはやRobot Exclusion Standardを含んでいません．

二番目に，メカニズムの知識はそれほどありませんが，個々のドキュメントの
著者をロボットでたどるファイルからリンクしたいかどうかを指定することも
可能です．これは`META'タグを以下のように使用します．

     <meta name="robots" content="nofollow">

   これは，<http://www.robotstxt.org/wc/meta-user.html>で幾分詳細に説
明されてます．Wgetは，通常の`/robots.txt'への排他的な追加で，ロボッ
ト除外のこの手法をサポートしています．

   ロボットの拒否を本当に，本当に望むことがどうなるか知っている場合，
`.wgetrc'の`robots'変数を`off'にして下さい．同じことは， 例えば`wget -e
robots=off URL...'のように，`-e'スイッ チで達成可能です．


File: wget-ja.info,  Node: Security Considerations,  Next: Contributors,  Prev: Robot Exclusion,  Up: Appendices

セキュリティの考慮
==================

Wgetを使用するとき，それが暗号化されていないパスワードをネットワークに
流すことを知っている必要があり，それはセキュリティの問題を提示するかも
しれません．ここに主な問題と，いくつかの解決があります．

  1. コマンドラインのパスワードは，`ps'の使用で見えるようになります．
     それを回避する最善策は，`wget -i -'を使用し，それぞれ分離された行
     になっていて`C-d'で終端したものをWgetの標準入力にURLとして与
     えることです．もう一つの回避方法はパスワードの保存に`.netrc'を使
     用することです．しかし，暗号化されていないパスワードもセキュリティの危
     機と考えられます．

  2. 安全でない"basic"認証方式を使用すると，暗号化されていないパスワー
     ドがネットワークのルータとゲートウェイを通じて転送されます．

  3. FTPパスワードも暗号化されません．現在これに関しては良い解決方法が
     ありません．

  4.
     Wgetの"通常の"出力はパスワードを隠そうとしますが，デバッグログは，あ
     らゆる形式でそれらを表示します．この問題は，バグの報告を送るとき注意す
     ることで避けます(そう，それらを私に送るときもです)．


File: wget-ja.info,  Node: Contributors,  Prev: Security Considerations,  Up: Appendices

寄稿者
======

   GNU WgetはHrvoje Niksic <hniksic@arsdigita.com>によって書かれま
した．
しかしその開発は，バグレポート，特徴の提案，パッチや"Thanks!"と書か
れた感謝状など，多くの人々の助けが無ければ非常に遠いものとなっていたは
ずです．

   以下の人々に特別な感謝を送ります(順不同)．

   * Karsten Thygesen--メーリングリスト，webスペース，そして初期のFTP
     スペースといった，システムリソースと，これらを実際に動作させる多くの時
     間の寄付．

   * Shawn McHorse--バグレポートとパッチ．

   * Kaveh R. Ghazi--毎度の`ansi2knr'変換．多くの移植性の修正．

   * Gordon Matzigkeit--`.netrc'サポート．

   * Zlatko Calusic, Tomislav Vujec and Drazen
     Kacar--特徴の提案と，"哲学 的な"議論．

   * Darko Budor--Windowsへの初期移植．

   * Antonio Rosella--助けと提案，そしてイタリア語翻訳．

   * Tomislav Petrovic, Mario Mikocevic--多くのバグレポートと提案．

   * Francois Pinard--多くの徹底的なバグレポートと議論．

   * Karl Eichwalder--国際化とその他の多くの手助け．

   * Junio Hamano--OpieとHTTP `Digest'認証に対するサポートの寄付．

   * Brian Goughを含め，開発に寄付を提供してくれた人々．

   以下の人々は，パッチ，バグ/ビルドレポート，役立つ提案，ベータテスト，
ファンメールと管理者が喜ばしいと感じるあらゆることを提供してくれました．

   Ian Abbott Tim Adam, Adrian Aichner, Martin Baehr, Dieter Baron,
Roger Beeman, Dan Berger, T. Bharath, Paul Bludov, Daniel Bodea, Mark
Boyns, John Burden, Wanderlei Cavassin, Gilles Cedoc, Tim Charron, Noel
Cragg, Kristijan Conkas, John Daily, Ahmon Dancy, Andrew Davison,
Andrew Deryabin, Ulrich Drepper, Marc Duponcheel, Damir Dzeko, Alan
Eldridge, Aleksandar Erkalovic, Andy Eskilsson, Christian Fraenkel,
Masashi Fujita, Howard Gayle, Marcel Gerrits, Lemble Gregory, Hans
Grobler, Mathieu Guillaume, Dan Harkless, Aaron Hawley, Herold Heiko,
Jochen Hein, Karl Heuer, HIROSE Masaaki, Gregor Hoffleit, Erik Magnus
Hulthen, Richard Huveneers, Jonas Jensen, Simon Josefsson, Mario Juric,
Hack Kampbjorn, Const Kaplinsky, Goran Kezunovic, Robert Kleine, KOJIMA
Haime, Fila Kolodny, Alexander Kourakos, Martin Kraemer, Simos
KSenitellis, Hrvoje Lacko, Daniel S. Lewart, Nicolas Lichtmeier, Dave
Love, Alexander V. Lukyanov, Thomas Lussnig, Aurelien Marchand, Jordan
Mendelson, Lin Zhe Min, Tim Mooney, Simon Munton, Charlie Negyesi, R.
K. Owen, Andrew Pollock, Steve Pothier, Jan Prikryl, Marin Purgar,
Csaba Raduly, Keith Refson, Bill Richardson, Tyler Riddle, Tobias
Ringstrom, Juan Jose Rodrigues, Maciej W. Rozycki, Edward J. Sabol,
Heinz Salzmann, Robert Schmidt, Andreas Schwab, Chris Seawood, Toomas
Soome, Tage Stabell-Kulo, Sven Sternberger, Markus Strasser, John
Summerfield, Szakacsits Szabolcs, Mike Thomas, Philipp Thomas, Mauro
Tortonesi, Dave Turner, Gisle Vanem, Russell Vincent, Charles G Waldman,
Douglas E. Wegscheid, Jasmin Zainul, Bojan Zdrnja, Kristijan Zimmer.

記載忘れの方へ謝罪し，そしてWgetメーリングリストの全ての方に多いに感謝
します．


File: wget-ja.info,  Node: Copying,  Next: Concept Index,  Prev: Appendices,  Up: Top

コピーについて
**************

   GNU Wget is licensed under the GNU GPL, which makes it "free
software".

   Please note that "free" in "free software" refers to liberty, not
price.  As some GNU project advocates like to point out, think of "free
speech" rather than "free beer".  The exact and legally binding
distribution terms are spelled out below; in short, you have the right
(freedom) to run and change Wget and distribute it to other people, and
even--if you want--charge money for doing either.  The important
restriction is that you have to grant your recipients the same rights
and impose the same restrictions.

   This method of licensing software is also known as "open source"
because, among other things, it makes sure that all recipients will
receive the source code along with the program, and be able to improve
it.  The GNU project prefers the term "free software" for reasons
outlined at
<http://www.gnu.org/philosophy/free-software-for-freedom.html>.

   The exact license terms are defined by this paragraph and the GNU
General Public License it refers to:

     GNU Wget is free software; you can redistribute it and/or modify it
     under the terms of the GNU General Public License as published by
     the Free Software Foundation; either version 2 of the License, or
     (at your option) any later version.

     GNU Wget is distributed in the hope that it will be useful, but
     WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
     General Public License for more details.

     A copy of the GNU General Public License is included as part of
     this manual; if you did not receive it, write to the Free Software
     Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.

   In addition to this, this manual is free in the same sense:

     Permission is granted to copy, distribute and/or modify this
     document under the terms of the GNU Free Documentation License,
     Version 1.1 or any later version published by the Free Software
     Foundation; with the Invariant Sections being "GNU General Public
     License" and "GNU Free Documentation License", with no Front-Cover
     Texts, and with no Back-Cover Texts.  A copy of the license is
     included in the section entitled "GNU Free Documentation License".

   The full texts of the GNU General Public License and of the GNU Free
Documentation License are available below.

* Menu:

* GNU General Public License::
* GNU Free Documentation License::


File: wget-ja.info,  Node: GNU General Public License,  Next: GNU Free Documentation License,  Prev: Copying,  Up: Copying

GNU General Public License
==========================

                         Version 2, June 1991
     Copyright (C) 1989, 1991 Free Software Foundation, Inc.
     675 Mass Ave, Cambridge, MA 02139, USA
     
     Everyone is permitted to copy and distribute verbatim copies
     of this license document, but changing it is not allowed.

Preamble
========

   The licenses for most software are designed to take away your
freedom to share and change it.  By contrast, the GNU General Public
License is intended to guarantee your freedom to share and change free
software--to make sure the software is free for all its users.  This
General Public License applies to most of the Free Software
Foundation's software and to any other program whose authors commit to
using it.  (Some other Free Software Foundation software is covered by
the GNU Library General Public License instead.)  You can apply it to
your programs, too.

   When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
this service if you wish), that you receive source code or can get it
if you want it, that you can change the software or use pieces of it in
new free programs; and that you know you can do these things.

   To protect your rights, we need to make restrictions that forbid
anyone to deny you these rights or to ask you to surrender the rights.
These restrictions translate to certain responsibilities for you if you
distribute copies of the software, or if you modify it.

   For example, if you distribute copies of such a program, whether
gratis or for a fee, you must give the recipients all the rights that
you have.  You must make sure that they, too, receive or can get the
source code.  And you must show them these terms so they know their
rights.

   We protect your rights with two steps: (1) copyright the software,
and (2) offer you this license which gives you legal permission to copy,
distribute and/or modify the software.

   Also, for each author's protection and ours, we want to make certain
that everyone understands that there is no warranty for this free
software.  If the software is modified by someone else and passed on, we
want its recipients to know that what they have is not the original, so
that any problems introduced by others will not reflect on the original
authors' reputations.

   Finally, any free program is threatened constantly by software
patents.  We wish to avoid the danger that redistributors of a free
program will individually obtain patent licenses, in effect making the
program proprietary.  To prevent this, we have made it clear that any
patent must be licensed for everyone's free use or not licensed at all.

   The precise terms and conditions for copying, distribution and
modification follow.

    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
  1. This License applies to any program or other work which contains a
     notice placed by the copyright holder saying it may be distributed
     under the terms of this General Public License.  The "Program",
     below, refers to any such program or work, and a "work based on
     the Program" means either the Program or any derivative work under
     copyright law: that is to say, a work containing the Program or a
     portion of it, either verbatim or with modifications and/or
     translated into another language.  (Hereinafter, translation is
     included without limitation in the term "modification".)  Each
     licensee is addressed as "you".

     Activities other than copying, distribution and modification are
     not covered by this License; they are outside its scope.  The act
     of running the Program is not restricted, and the output from the
     Program is covered only if its contents constitute a work based on
     the Program (independent of having been made by running the
     Program).  Whether that is true depends on what the Program does.

  2. You may copy and distribute verbatim copies of the Program's
     source code as you receive it, in any medium, provided that you
     conspicuously and appropriately publish on each copy an appropriate
     copyright notice and disclaimer of warranty; keep intact all the
     notices that refer to this License and to the absence of any
     warranty; and give any other recipients of the Program a copy of
     this License along with the Program.

     You may charge a fee for the physical act of transferring a copy,
     and you may at your option offer warranty protection in exchange
     for a fee.

  3. You may modify your copy or copies of the Program or any portion
     of it, thus forming a work based on the Program, and copy and
     distribute such modifications or work under the terms of Section 1
     above, provided that you also meet all of these conditions:

       a. You must cause the modified files to carry prominent notices
          stating that you changed the files and the date of any change.

       b. You must cause any work that you distribute or publish, that
          in whole or in part contains or is derived from the Program
          or any part thereof, to be licensed as a whole at no charge
          to all third parties under the terms of this License.

       c. If the modified program normally reads commands interactively
          when run, you must cause it, when started running for such
          interactive use in the most ordinary way, to print or display
          an announcement including an appropriate copyright notice and
          a notice that there is no warranty (or else, saying that you
          provide a warranty) and that users may redistribute the
          program under these conditions, and telling the user how to
          view a copy of this License.  (Exception: if the Program
          itself is interactive but does not normally print such an
          announcement, your work based on the Program is not required
          to print an announcement.)

     These requirements apply to the modified work as a whole.  If
     identifiable sections of that work are not derived from the
     Program, and can be reasonably considered independent and separate
     works in themselves, then this License, and its terms, do not
     apply to those sections when you distribute them as separate
     works.  But when you distribute the same sections as part of a
     whole which is a work based on the Program, the distribution of
     the whole must be on the terms of this License, whose permissions
     for other licensees extend to the entire whole, and thus to each
     and every part regardless of who wrote it.

     Thus, it is not the intent of this section to claim rights or
     contest your rights to work written entirely by you; rather, the
     intent is to exercise the right to control the distribution of
     derivative or collective works based on the Program.

     In addition, mere aggregation of another work not based on the
     Program with the Program (or with a work based on the Program) on
     a volume of a storage or distribution medium does not bring the
     other work under the scope of this License.

  4. You may copy and distribute the Program (or a work based on it,
     under Section 2) in object code or executable form under the terms
     of Sections 1 and 2 above provided that you also do one of the
     following:

       a. Accompany it with the complete corresponding machine-readable
          source code, which must be distributed under the terms of
          Sections 1 and 2 above on a medium customarily used for
          software interchange; or,

       b. Accompany it with a written offer, valid for at least three
          years, to give any third party, for a charge no more than your
          cost of physically performing source distribution, a complete
          machine-readable copy of the corresponding source code, to be
          distributed under the terms of Sections 1 and 2 above on a
          medium customarily used for software interchange; or,

       c. Accompany it with the information you received as to the offer
          to distribute corresponding source code.  (This alternative is
          allowed only for noncommercial distribution and only if you
          received the program in object code or executable form with
          such an offer, in accord with Subsection b above.)

     The source code for a work means the preferred form of the work for
     making modifications to it.  For an executable work, complete
     source code means all the source code for all modules it contains,
     plus any associated interface definition files, plus the scripts
     used to control compilation and installation of the executable.
     However, as a special exception, the source code distributed need
     not include anything that is normally distributed (in either
     source or binary form) with the major components (compiler,
     kernel, and so on) of the operating system on which the executable
     runs, unless that component itself accompanies the executable.

     If distribution of executable or object code is made by offering
     access to copy from a designated place, then offering equivalent
     access to copy the source code from the same place counts as
     distribution of the source code, even though third parties are not
     compelled to copy the source along with the object code.

  5. You may not copy, modify, sublicense, or distribute the Program
     except as expressly provided under this License.  Any attempt
     otherwise to copy, modify, sublicense or distribute the Program is
     void, and will automatically terminate your rights under this
     License.  However, parties who have received copies, or rights,
     from you under this License will not have their licenses
     terminated so long as such parties remain in full compliance.

  6. You are not required to accept this License, since you have not
     signed it.  However, nothing else grants you permission to modify
     or distribute the Program or its derivative works.  These actions
     are prohibited by law if you do not accept this License.
     Therefore, by modifying or distributing the Program (or any work
     based on the Program), you indicate your acceptance of this
     License to do so, and all its terms and conditions for copying,
     distributing or modifying the Program or works based on it.

  7. Each time you redistribute the Program (or any work based on the
     Program), the recipient automatically receives a license from the
     original licensor to copy, distribute or modify the Program
     subject to these terms and conditions.  You may not impose any
     further restrictions on the recipients' exercise of the rights
     granted herein.  You are not responsible for enforcing compliance
     by third parties to this License.

  8. If, as a consequence of a court judgment or allegation of patent
     infringement or for any other reason (not limited to patent
     issues), conditions are imposed on you (whether by court order,
     agreement or otherwise) that contradict the conditions of this
     License, they do not excuse you from the conditions of this
     License.  If you cannot distribute so as to satisfy simultaneously
     your obligations under this License and any other pertinent
     obligations, then as a consequence you may not distribute the
     Program at all.  For example, if a patent license would not permit
     royalty-free redistribution of the Program by all those who
     receive copies directly or indirectly through you, then the only
     way you could satisfy both it and this License would be to refrain
     entirely from distribution of the Program.

     If any portion of this section is held invalid or unenforceable
     under any particular circumstance, the balance of the section is
     intended to apply and the section as a whole is intended to apply
     in other circumstances.

     It is not the purpose of this section to induce you to infringe any
     patents or other property right claims or to contest validity of
     any such claims; this section has the sole purpose of protecting
     the integrity of the free software distribution system, which is
     implemented by public license practices.  Many people have made
     generous contributions to the wide range of software distributed
     through that system in reliance on consistent application of that
     system; it is up to the author/donor to decide if he or she is
     willing to distribute software through any other system and a
     licensee cannot impose that choice.

     This section is intended to make thoroughly clear what is believed
     to be a consequence of the rest of this License.

  9. If the distribution and/or use of the Program is restricted in
     certain countries either by patents or by copyrighted interfaces,
     the original copyright holder who places the Program under this
     License may add an explicit geographical distribution limitation
     excluding those countries, so that distribution is permitted only
     in or among countries not thus excluded.  In such case, this
     License incorporates the limitation as if written in the body of
     this License.

 10. The Free Software Foundation may publish revised and/or new
     versions of the General Public License from time to time.  Such
     new versions will be similar in spirit to the present version, but
     may differ in detail to address new problems or concerns.

     Each version is given a distinguishing version number.  If the
     Program specifies a version number of this License which applies
     to it and "any later version", you have the option of following
     the terms and conditions either of that version or of any later
     version published by the Free Software Foundation.  If the Program
     does not specify a version number of this License, you may choose
     any version ever published by the Free Software Foundation.

 11. If you wish to incorporate parts of the Program into other free
     programs whose distribution conditions are different, write to the
     author to ask for permission.  For software which is copyrighted
     by the Free Software Foundation, write to the Free Software
     Foundation; we sometimes make exceptions for this.  Our decision
     will be guided by the two goals of preserving the free status of
     all derivatives of our free software and of promoting the sharing
     and reuse of software generally.

                                NO WARRANTY

 12. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO
     WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE
     LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
     HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT
     WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT
     NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
     FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE
     QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
     PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY
     SERVICING, REPAIR OR CORRECTION.

 13. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
     WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY
     MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE
     LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL,
     INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR
     INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
     DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU
     OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY
     OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN
     ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.

                      END OF TERMS AND CONDITIONS

How to Apply These Terms to Your New Programs
=============================================

   If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these
terms.

   To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
convey the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

     ONE LINE TO GIVE THE PROGRAM'S NAME AND AN IDEA OF WHAT IT DOES.
     Copyright (C) 19YY  NAME OF AUTHOR
     
     This program is free software; you can redistribute it and/or
     modify it under the terms of the GNU General Public License
     as published by the Free Software Foundation; either version 2
     of the License, or (at your option) any later version.
     
     This program is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU General Public License for more details.
     
     You should have received a copy of the GNU General Public License
     along with this program; if not, write to the Free Software
     Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.

   Also add information on how to contact you by electronic and paper
mail.

   If the program is interactive, make it output a short notice like
this when it starts in an interactive mode:

     Gnomovision version 69, Copyright (C) 19YY NAME OF AUTHOR
     Gnomovision comes with ABSOLUTELY NO WARRANTY; for details
     type `show w'.  This is free software, and you are welcome
     to redistribute it under certain conditions; type `show c'
     for details.

   The hypothetical commands `show w' and `show c' should show the
appropriate parts of the General Public License.  Of course, the
commands you use may be called something other than `show w' and `show
c'; they could even be mouse-clicks or menu items--whatever suits your
program.

   You should also get your employer (if you work as a programmer) or
your school, if any, to sign a "copyright disclaimer" for the program,
if necessary.  Here is a sample; alter the names:

     Yoyodyne, Inc., hereby disclaims all copyright
     interest in the program `Gnomovision'
     (which makes passes at compilers) written
     by James Hacker.
     
     SIGNATURE OF TY COON, 1 April 1989
     Ty Coon, President of Vice

   This General Public License does not permit incorporating your
program into proprietary programs.  If your program is a subroutine
library, you may consider it more useful to permit linking proprietary
applications with the library.  If this is what you want to do, use the
GNU Library General Public License instead of this License.


File: wget-ja.info,  Node: GNU Free Documentation License,  Prev: GNU General Public License,  Up: Copying

GNU Free Documentation License
==============================

                        Version 1.1, March 2000
     Copyright (C) 2000  Free Software Foundation, Inc.
     59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
     
     Everyone is permitted to copy and distribute verbatim copies
     of this license document, but changing it is not allowed.


  0. PREAMBLE

     The purpose of this License is to make a manual, textbook, or other
     written document "free" in the sense of freedom: to assure everyone
     the effective freedom to copy and redistribute it, with or without
     modifying it, either commercially or noncommercially.  Secondarily,
     this License preserves for the author and publisher a way to get
     credit for their work, while not being considered responsible for
     modifications made by others.

     This License is a kind of "copyleft", which means that derivative
     works of the document must themselves be free in the same sense.
     It complements the GNU General Public License, which is a copyleft
     license designed for free software.

     We have designed this License in order to use it for manuals for
     free software, because free software needs free documentation: a
     free program should come with manuals providing the same freedoms
     that the software does.  But this License is not limited to
     software manuals; it can be used for any textual work, regardless
     of subject matter or whether it is published as a printed book.
     We recommend this License principally for works whose purpose is
     instruction or reference.


  1. APPLICABILITY AND DEFINITIONS

     This License applies to any manual or other work that contains a
     notice placed by the copyright holder saying it can be distributed
     under the terms of this License.  The "Document", below, refers to
     any such manual or work.  Any member of the public is a licensee,
     and is addressed as "you".

     A "Modified Version" of the Document means any work containing the
     Document or a portion of it, either copied verbatim, or with
     modifications and/or translated into another language.

     A "Secondary Section" is a named appendix or a front-matter
     section of the Document that deals exclusively with the
     relationship of the publishers or authors of the Document to the
     Document's overall subject (or to related matters) and contains
     nothing that could fall directly within that overall subject.
     (For example, if the Document is in part a textbook of
     mathematics, a Secondary Section may not explain any mathematics.)
     The relationship could be a matter of historical connection with
     the subject or with related matters, or of legal, commercial,
     philosophical, ethical or political position regarding them.

     The "Invariant Sections" are certain Secondary Sections whose
     titles are designated, as being those of Invariant Sections, in
     the notice that says that the Document is released under this
     License.

     The "Cover Texts" are certain short passages of text that are
     listed, as Front-Cover Texts or Back-Cover Texts, in the notice
     that says that the Document is released under this License.

     A "Transparent" copy of the Document means a machine-readable copy,
     represented in a format whose specification is available to the
     general public, whose contents can be viewed and edited directly
     and straightforwardly with generic text editors or (for images
     composed of pixels) generic paint programs or (for drawings) some
     widely available drawing editor, and that is suitable for input to
     text formatters or for automatic translation to a variety of
     formats suitable for input to text formatters.  A copy made in an
     otherwise Transparent file format whose markup has been designed
     to thwart or discourage subsequent modification by readers is not
     Transparent.  A copy that is not "Transparent" is called "Opaque".

     Examples of suitable formats for Transparent copies include plain
     ASCII without markup, Texinfo input format, LaTeX input format,
     SGML or XML using a publicly available DTD, and
     standard-conforming simple HTML designed for human modification.
     Opaque formats include PostScript, PDF, proprietary formats that
     can be read and edited only by proprietary word processors, SGML
     or XML for which the DTD and/or processing tools are not generally
     available, and the machine-generated HTML produced by some word
     processors for output purposes only.

     The "Title Page" means, for a printed book, the title page itself,
     plus such following pages as are needed to hold, legibly, the
     material this License requires to appear in the title page.  For
     works in formats which do not have any title page as such, "Title
     Page" means the text near the most prominent appearance of the
     work's title, preceding the beginning of the body of the text.

  2. VERBATIM COPYING

     You may copy and distribute the Document in any medium, either
     commercially or noncommercially, provided that this License, the
     copyright notices, and the license notice saying this License
     applies to the Document are reproduced in all copies, and that you
     add no other conditions whatsoever to those of this License.  You
     may not use technical measures to obstruct or control the reading
     or further copying of the copies you make or distribute.  However,
     you may accept compensation in exchange for copies.  If you
     distribute a large enough number of copies you must also follow
     the conditions in section 3.

     You may also lend copies, under the same conditions stated above,
     and you may publicly display copies.

  3. COPYING IN QUANTITY

     If you publish printed copies of the Document numbering more than
     100, and the Document's license notice requires Cover Texts, you
     must enclose the copies in covers that carry, clearly and legibly,
     all these Cover Texts: Front-Cover Texts on the front cover, and
     Back-Cover Texts on the back cover.  Both covers must also clearly
     and legibly identify you as the publisher of these copies.  The
     front cover must present the full title with all words of the
     title equally prominent and visible.  You may add other material
     on the covers in addition.  Copying with changes limited to the
     covers, as long as they preserve the title of the Document and
     satisfy these conditions, can be treated as verbatim copying in
     other respects.

     If the required texts for either cover are too voluminous to fit
     legibly, you should put the first ones listed (as many as fit
     reasonably) on the actual cover, and continue the rest onto
     adjacent pages.

     If you publish or distribute Opaque copies of the Document
     numbering more than 100, you must either include a
     machine-readable Transparent copy along with each Opaque copy, or
     state in or with each Opaque copy a publicly-accessible
     computer-network location containing a complete Transparent copy
     of the Document, free of added material, which the general
     network-using public has access to download anonymously at no
     charge using public-standard network protocols.  If you use the
     latter option, you must take reasonably prudent steps, when you
     begin distribution of Opaque copies in quantity, to ensure that
     this Transparent copy will remain thus accessible at the stated
     location until at least one year after the last time you
     distribute an Opaque copy (directly or through your agents or
     retailers) of that edition to the public.

     It is requested, but not required, that you contact the authors of
     the Document well before redistributing any large number of
     copies, to give them a chance to provide you with an updated
     version of the Document.

  4. MODIFICATIONS

     You may copy and distribute a Modified Version of the Document
     under the conditions of sections 2 and 3 above, provided that you
     release the Modified Version under precisely this License, with
     the Modified Version filling the role of the Document, thus
     licensing distribution and modification of the Modified Version to
     whoever possesses a copy of it.  In addition, you must do these
     things in the Modified Version:

     A. Use in the Title Page (and on the covers, if any) a title
     distinct    from that of the Document, and from those of previous
     versions    (which should, if there were any, be listed in the
     History section    of the Document).  You may use the same title
     as a previous version    if the original publisher of that version
     gives permission.
     B. List on the Title Page, as authors, one or more persons or
     entities    responsible for authorship of the modifications in the
     Modified    Version, together with at least five of the principal
     authors of the    Document (all of its principal authors, if it
     has less than five).
     C. State on the Title page the name of the publisher of the
     Modified Version, as the publisher.
     D. Preserve all the copyright notices of the Document.
     E. Add an appropriate copyright notice for your modifications
     adjacent to the other copyright notices.
     F. Include, immediately after the copyright notices, a license
     notice    giving the public permission to use the Modified Version
     under the    terms of this License, in the form shown in the
     Addendum below.
     G. Preserve in that license notice the full lists of Invariant
     Sections    and required Cover Texts given in the Document's
     license notice.
     H. Include an unaltered copy of this License.
     I. Preserve the section entitled "History", and its title, and add
     to    it an item stating at least the title, year, new authors, and
       publisher of the Modified Version as given on the Title Page.
     If    there is no section entitled "History" in the Document,
     create one    stating the title, year, authors, and publisher of
     the Document as    given on its Title Page, then add an item
     describing the Modified    Version as stated in the previous
     sentence.
     J. Preserve the network location, if any, given in the Document for
       public access to a Transparent copy of the Document, and
     likewise    the network locations given in the Document for
     previous versions    it was based on.  These may be placed in the
     "History" section.     You may omit a network location for a work
     that was published at    least four years before the Document
     itself, or if the original    publisher of the version it refers
     to gives permission.
     K. In any section entitled "Acknowledgements" or "Dedications",
     preserve the section's title, and preserve in the section all the
      substance and tone of each of the contributor acknowledgements
     and/or dedications given therein.
     L. Preserve all the Invariant Sections of the Document,
     unaltered in their text and in their titles.  Section numbers
     or the equivalent are not considered part of the section titles.
     M. Delete any section entitled "Endorsements".  Such a section
     may not be included in the Modified Version.
     N. Do not retitle any existing section as "Endorsements"    or to
     conflict in title with any Invariant Section.

     If the Modified Version includes new front-matter sections or
     appendices that qualify as Secondary Sections and contain no
     material copied from the Document, you may at your option
     designate some or all of these sections as invariant.  To do this,
     add their titles to the list of Invariant Sections in the Modified
     Version's license notice.  These titles must be distinct from any
     other section titles.

     You may add a section entitled "Endorsements", provided it contains
     nothing but endorsements of your Modified Version by various
     parties-for example, statements of peer review or that the text has
     been approved by an organization as the authoritative definition
     of a standard.

     You may add a passage of up to five words as a Front-Cover Text,
     and a passage of up to 25 words as a Back-Cover Text, to the end
     of the list of Cover Texts in the Modified Version.  Only one
     passage of Front-Cover Text and one of Back-Cover Text may be
     added by (or through arrangements made by) any one entity.  If the
     Document already includes a cover text for the same cover,
     previously added by you or by arrangement made by the same entity
     you are acting on behalf of, you may not add another; but you may
     replace the old one, on explicit permission from the previous
     publisher that added the old one.

     The author(s) and publisher(s) of the Document do not by this
     License give permission to use their names for publicity for or to
     assert or imply endorsement of any Modified Version.

  5. COMBINING DOCUMENTS

     You may combine the Document with other documents released under
     this License, under the terms defined in section 4 above for
     modified versions, provided that you include in the combination
     all of the Invariant Sections of all of the original documents,
     unmodified, and list them all as Invariant Sections of your
     combined work in its license notice.

     The combined work need only contain one copy of this License, and
     multiple identical Invariant Sections may be replaced with a single
     copy.  If there are multiple Invariant Sections with the same name
     but different contents, make the title of each such section unique
     by adding at the end of it, in parentheses, the name of the
     original author or publisher of that section if known, or else a
     unique number.  Make the same adjustment to the section titles in
     the list of Invariant Sections in the license notice of the
     combined work.

     In the combination, you must combine any sections entitled
     "History" in the various original documents, forming one section
     entitled "History"; likewise combine any sections entitled
     "Acknowledgements", and any sections entitled "Dedications".  You
     must delete all sections entitled "Endorsements."

  6. COLLECTIONS OF DOCUMENTS

     You may make a collection consisting of the Document and other
     documents released under this License, and replace the individual
     copies of this License in the various documents with a single copy
     that is included in the collection, provided that you follow the
     rules of this License for verbatim copying of each of the
     documents in all other respects.

     You may extract a single document from such a collection, and
     distribute it individually under this License, provided you insert
     a copy of this License into the extracted document, and follow
     this License in all other respects regarding verbatim copying of
     that document.

  7. AGGREGATION WITH INDEPENDENT WORKS

     A compilation of the Document or its derivatives with other
     separate and independent documents or works, in or on a volume of
     a storage or distribution medium, does not as a whole count as a
     Modified Version of the Document, provided no compilation
     copyright is claimed for the compilation.  Such a compilation is
     called an "aggregate", and this License does not apply to the
     other self-contained works thus compiled with the Document, on
     account of their being thus compiled, if they are not themselves
     derivative works of the Document.

     If the Cover Text requirement of section 3 is applicable to these
     copies of the Document, then if the Document is less than one
     quarter of the entire aggregate, the Document's Cover Texts may be
     placed on covers that surround only the Document within the
     aggregate.  Otherwise they must appear on covers around the whole
     aggregate.

  8. TRANSLATION

     Translation is considered a kind of modification, so you may
     distribute translations of the Document under the terms of section
     4.  Replacing Invariant Sections with translations requires special
     permission from their copyright holders, but you may include
     translations of some or all Invariant Sections in addition to the
     original versions of these Invariant Sections.  You may include a
     translation of this License provided that you also include the
     original English version of this License.  In case of a
     disagreement between the translation and the original English
     version of this License, the original English version will prevail.

  9. TERMINATION

     You may not copy, modify, sublicense, or distribute the Document
     except as expressly provided for under this License.  Any other
     attempt to copy, modify, sublicense or distribute the Document is
     void, and will automatically terminate your rights under this
     License.  However, parties who have received copies, or rights,
     from you under this License will not have their licenses
     terminated so long as such parties remain in full compliance.

 10. FUTURE REVISIONS OF THIS LICENSE

     The Free Software Foundation may publish new, revised versions of
     the GNU Free Documentation License from time to time.  Such new
     versions will be similar in spirit to the present version, but may
     differ in detail to address new problems or concerns.  See
     http://www.gnu.org/copyleft/.

     Each version of the License is given a distinguishing version
     number.  If the Document specifies that a particular numbered
     version of this License "or any later version" applies to it, you
     have the option of following the terms and conditions either of
     that specified version or of any later version that has been
     published (not as a draft) by the Free Software Foundation.  If
     the Document does not specify a version number of this License,
     you may choose any version ever published (not as a draft) by the
     Free Software Foundation.


ADDENDUM: How to use this License for your documents
====================================================

   To use this License in a document you have written, include a copy of
the License in the document and put the following copyright and license
notices just after the title page:


       Copyright (C)  YEAR  YOUR NAME.
       Permission is granted to copy, distribute and/or modify this document
       under the terms of the GNU Free Documentation License, Version 1.1
       or any later version published by the Free Software Foundation;
       with the Invariant Sections being LIST THEIR TITLES, with the
       Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.
       A copy of the license is included in the section entitled ``GNU
       Free Documentation License''.
If you have no Invariant Sections, write "with no Invariant
Sections" instead of saying which ones are invariant.  If you have no
Front-Cover Texts, write "no Front-Cover Texts" instead of "Front-Cover
Texts being LIST"; likewise for Back-Cover Texts.

   If your document contains nontrivial examples of program code, we
recommend releasing these examples in parallel under your choice of
free software license, such as the GNU General Public License, to
permit their use in free software.


File: wget-ja.info,  Node: Concept Index,  Prev: Copying,  Up: Top

概念の索引
**********

* Menu:

* .html extension:                       HTTP Options.
* .listing files, removing:              FTP Options.
* .netrc:                                Startup File.
* .wgetrc:                               Startup File.
* accept directories:                    Directory-Based Limits.
* accept suffixes:                       Types of Files.
* accept wildcards:                      Types of Files.
* append to log:                         Logging and Input File Options.
* arguments:                             Invoking.
* authentication:                        HTTP Options.
* backing up converted files:            Recursive Retrieval Options.
* bandwidth, limit:                      Download Options.
* base for relative links in input file: Logging and Input File Options.
* bind() address:                        Download Options.
* bug reports:                           Reporting Bugs.
* bugs:                                  Reporting Bugs.
* cache:                                 HTTP Options.
* caching of DNS lookups:                Download Options.
* client IP address:                     Download Options.
* clobbering, file:                      Download Options.
* command line:                          Invoking.
* comments, HTML:                        Recursive Retrieval Options.
* connect timeout:                       Download Options.
* Content-Length, ignore:                HTTP Options.
* continue retrieval:                    Download Options.
* contributors:                          Contributors.
* conversion of links:                   Recursive Retrieval Options.
* cookies:                               HTTP Options.
* cookies, loading:                      HTTP Options.
* cookies, saving:                       HTTP Options.
* copying:                               Copying.
* cut directories:                       Directory Options.
* debug:                                 Logging and Input File Options.
* delete after retrieval:                Recursive Retrieval Options.
* directories:                           Directory-Based Limits.
* directories, exclude:                  Directory-Based Limits.
* directories, include:                  Directory-Based Limits.
* directory limits:                      Directory-Based Limits.
* directory prefix:                      Directory Options.
* DNS cache:                             Download Options.
* DNS timeout:                           Download Options.
* dot style:                             Download Options.
* downloading multiple times:            Download Options.
* examples:                              Examples.
* exclude directories:                   Directory-Based Limits.
* execute wgetrc command:                Basic Startup Options.
* features:                              Overview.
* file names, restrict:                  Download Options.
* filling proxy cache:                   Recursive Retrieval Options.
* follow FTP links:                      Recursive Accept/Reject Options.
* following ftp links:                   FTP Links.
* following links:                       Following Links.
* force html:                            Logging and Input File Options.
* free software:                         Copying.
* ftp time-stamping:                     FTP Time-Stamping Internals.
* GFDL:                                  Copying.
* globbing, toggle:                      FTP Options.
* GPL:                                   Copying.
* hangup:                                Signals.
* header, add:                           HTTP Options.
* hosts, spanning:                       Spanning Hosts.
* HTML comments:                         Recursive Retrieval Options.
* http password:                         HTTP Options.
* http referer:                          HTTP Options.
* http time-stamping:                    HTTP Time-Stamping Internals.
* http user:                             HTTP Options.
* ignore length:                         HTTP Options.
* include directories:                   Directory-Based Limits.
* incomplete downloads:                  Download Options.
* incremental updating:                  Time-Stamping.
* input-file:                            Logging and Input File Options.
* invoking:                              Invoking.
* IP address, client:                    Download Options.
* latest version:                        Distribution.
* limit bandwidth:                       Download Options.
* link conversion:                       Recursive Retrieval Options.
* links:                                 Following Links.
* list:                                  Mailing List.
* loading cookies:                       HTTP Options.
* location of wgetrc:                    Wgetrc Location.
* log file:                              Logging and Input File Options.
* mailing list:                          Mailing List.
* mirroring:                             Very Advanced Usage.
* no parent:                             Directory-Based Limits.
* no warranty:                           GNU General Public License.
* no-clobber:                            Download Options.
* nohup:                                 Invoking.
* number of retries:                     Download Options.
* operating systems:                     Portability.
* option syntax:                         Option Syntax.
* output file:                           Logging and Input File Options.
* overview:                              Overview.
* page requisites:                       Recursive Retrieval Options.
* passive ftp:                           FTP Options.
* pause:                                 Download Options.
* portability:                           Portability.
* POST:                                  HTTP Options.
* progress indicator:                    Download Options.
* proxies:                               Proxies.
* proxy <1>:                             Download Options.
* proxy:                                 HTTP Options.
* proxy authentication:                  HTTP Options.
* proxy filling:                         Recursive Retrieval Options.
* proxy password:                        HTTP Options.
* proxy user:                            HTTP Options.
* quiet:                                 Logging and Input File Options.
* quota:                                 Download Options.
* random wait:                           Download Options.
* rate, limit:                           Download Options.
* read timeout:                          Download Options.
* recursion:                             Recursive Retrieval.
* recursive retrieval:                   Recursive Retrieval.
* redirecting output:                    Advanced Usage.
* referer, http:                         HTTP Options.
* reject directories:                    Directory-Based Limits.
* reject suffixes:                       Types of Files.
* reject wildcards:                      Types of Files.
* relative links:                        Relative Links.
* reporting bugs:                        Reporting Bugs.
* required images, downloading:          Recursive Retrieval Options.
* resume download:                       Download Options.
* retries:                               Download Options.
* retries, waiting between:              Download Options.
* retrieving:                            Recursive Retrieval.
* robot exclusion:                       Robot Exclusion.
* robots.txt:                            Robot Exclusion.
* sample wgetrc:                         Sample Wgetrc.
* saving cookies:                        HTTP Options.
* security:                              Security Considerations.
* server maintenance:                    Robot Exclusion.
* server response, print:                Download Options.
* server response, save:                 HTTP Options.
* signal handling:                       Signals.
* spanning hosts:                        Spanning Hosts.
* spider:                                Download Options.
* startup:                               Startup File.
* startup file:                          Startup File.
* suffixes, accept:                      Types of Files.
* suffixes, reject:                      Types of Files.
* symbolic links, retrieving:            FTP Options.
* syntax of options:                     Option Syntax.
* syntax of wgetrc:                      Wgetrc Syntax.
* tag-based recursive pruning:           Recursive Accept/Reject Options.
* time-stamping:                         Time-Stamping.
* time-stamping usage:                   Time-Stamping Usage.
* timeout:                               Download Options.
* timeout, connect:                      Download Options.
* timeout, DNS:                          Download Options.
* timeout, read:                         Download Options.
* timestamping:                          Time-Stamping.
* tries:                                 Download Options.
* types of files:                        Types of Files.
* updating the archives:                 Time-Stamping.
* URL:                                   URL Format.
* URL syntax:                            URL Format.
* usage, time-stamping:                  Time-Stamping Usage.
* user-agent:                            HTTP Options.
* various:                               Various.
* verbose:                               Logging and Input File Options.
* wait:                                  Download Options.
* wait, random:                          Download Options.
* waiting between retries:               Download Options.
* Wget as spider:                        Download Options.
* wgetrc:                                Startup File.
* wgetrc commands:                       Wgetrc Commands.
* wgetrc location:                       Wgetrc Location.
* wgetrc syntax:                         Wgetrc Syntax.
* wildcards, accept:                     Types of Files.
* wildcards, reject:                     Types of Files.
* Windows file names:                    Download Options.



Tag table:
Node: Top992
Node: Overview1878
Node: Invoking3900
Node: URL Format4556
Node: Option Syntax6235
Node: Basic Startup Options7200
Node: Logging and Input File Options7741
Node: Download Options9389
Node: Directory Options18941
Node: HTTP Options20666
Node: FTP Options27067
Node: Recursive Retrieval Options29074
Node: Recursive Accept/Reject Options34110
Node: Recursive Retrieval36098
Node: Following Links37898
Node: Spanning Hosts38558
Node: Types of Files39914
Node: Directory-Based Limits41452
Node: Relative Links43174
Node: FTP Links43769
Node: Time-Stamping44275
Node: Time-Stamping Usage45604
Node: HTTP Time-Stamping Internals46780
Node: FTP Time-Stamping Internals47708
Node: Startup File48611
Node: Wgetrc Location49248
Node: Wgetrc Syntax49798
Node: Wgetrc Commands50271
Node: Sample Wgetrc57593
Node: Examples62486
Node: Simple Usage62766
Node: Advanced Usage63744
Node: Very Advanced Usage66301
Node: Various67427
Node: Proxies67916
Node: Distribution69519
Node: Mailing List69768
Node: Reporting Bugs70308
Node: Portability71395
Node: Signals72251
Node: Appendices72694
Node: Robot Exclusion72977
Node: Security Considerations75250
Node: Contributors75980
Node: Copying78565
Node: GNU General Public License81186
Node: GNU Free Documentation License100387
Node: Concept Index120109

End tag table
